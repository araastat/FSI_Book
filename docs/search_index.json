[
["index.html", "Welcome", " PS 312: Programming with R Course Notes Abhijit Dasgupta, PhD Last updated: March 27, 2019 Welcome This course is an introduction to the statistical programming language R and various applications. We will cover the entire data analytics pipeline from data ingestion to data wrangling, summarizing, modeling, visualizing and reporting, all using tools found within the R ecosystem. The version of these notes you are reading now was built on 2019-03-27. To raise an issue about the note’s content (e.g., code not running) or to make a feature request, check out the issue tracker. "],
["reproducibility.html", "Reproducibility", " Reproducibility These notes are written with bookdown, a R package for writing books using rmarkdown. All code in these notes were developed on R version 3.5.0 (2018-04-23), using the same packages pre-installed in your virtual machines. When you’re on your own, you will need to install a recent version of R, and also install the corresponding packages, on your computer, for all the code to work. A listing of all the packages used in this course will be available as an appendix. To build these notes locally, clone or download the Github repo hosting these notes, unzip it if necessary, and double-click on FSI_Book.Rproj. Assuming you have RStudio installed, this will open this project (more on RStudio Projects later). You can then go to the console and enter the following code:{r, eval = F} bookdown::render_book(&quot;index.Rmd&quot;) # to build these notes browseURL(&quot;_book/index.html&quot;) # to view it "],
["what-is-r.html", "Chapter 1 What is R?", " Chapter 1 What is R? R is the most popular1 open source statistical programming language in the world. It allows you to read datasets written in a wide variety of formats, clean and process the data, derive summaries, run analytics, visualize create automated reports, presentations, websites, dashboards and interactive applications R is not just a language, but an ecosystem comprising over 15,000 user- and corporation-developed packages or modules, all written in the R language for a variety of purposes. It is a very flexible and customizable language, which is why it is used by an estimated 2 million users worldwide for data analytics. The question R users often ask is not “Can it be done?” but rather “How can it be done?”. R is used in areas as varied as healthcare, economics, forestry, oceanography, pharmaceuticals, artificial intelligence and natural language processing. Why is R so widely used? Some reasons are: R is open source, so it is accessible to anyone with a computer Since the code in R and all its packages are open, the community of users can help debug it and make it more reliable and robust The R ecosystem is very rich in tools for doing data analytics in particular, so there is almost certainly something available for almost any task The community of R users worldwide is a very strong, well-connected group who are welcoming, ready to help, cooperative and inclusive. Many users find this community to be one of the most attractive things about R R produces really nice customizable visualizations with relatively little effort, which was one of the first reasons for popularity. https://spectrum.ieee.org/static/interactive-the-top-programming-languages-2018↩ "],
["a-note-on-coding-and-programming.html", "A note on coding and programming", " A note on coding and programming R does not have a point-and-click interface that you are probably more familiar with from Excel, Word or other computer applications. It requires you to code, i.e. write instructions for the computer to, in the case of R, read, analyze, graph and report on datasets. R is first and foremost a language. So, instead of thinking that this is some geeky thing that “programmers” and “IT people” do, think of it as learning a language. You will see that, like any language, it has nouns, verbs, adjectives and adverbs, and you can create “sentences” that start with data and end in something useful like a table, graph or document. With a traditional spoken and written language like French, Arabic, Farsi or Japanese, you learn it to be able to interact with people at different posts around the world. With a programming language like R, you will be able to interact with data, to make sense of it, to describe it, and to present it. Coding Coding is writing explicit instructions to a very literal, and in some ways, stupid machine. The machine takes our code literally, and will do exactly what you tell it to do in the code. If you are getting unexpected results, it’s almost certainly your code that needs to be checked, not the machine. R, the language As we will see, R has many elements of a language. Objects: These are the nouns. We will act on objects to create new objects. Each object has a name which we will treat as the nouns in our code. Functions: These are the verbs. Functions will act on objects to create new objects. The %&gt;% operator: This acts like the conjunction “then” to create “sentences” called pipes or chains. Optional function arguments: These are adverbs which modify the action of the function (verb). While writing code in R, we should be aware that R is case-sensitive, so mydata is a different object than myData which is also different from Mydata and My_Data and MyData and my_data, and mean, which is a function in R, is different from Mean which is not defined in R. You have to name all the objects you create in R if you want to see them again. Try and pick a naming system that is simple yet descriptive, rather than data1. Two typical conventions that are used are CamelCase and pothole_case. So you could name a dataset of operational budgets for January, 2019 as operations_budget_2019_jan or OperationsBudget2019Jan or really anything you want, as long as it’s clear to you and doesn’t include some forbidden characters like -, @,$ which are reserved for other purposes, or doesn’t start with a number. Some people have a system where data objects (which are called data.frame or tibble or vector or matrix) should be capitalized, while function names should not. Data objects should probably be nouns and functions verbs, since that reminds us of their functions. There are different opinions. Some influential ones are here and here. As they say, finding a good name is hard, but often worth the effort. The ultimate goal for every script file is to create a “story” using the language of R, starting from data to create descriptions, understand patterns through visualization and modeling, and analyzing the data in general. Scripts make this story reproducible, and also transferable to different data sets. Of course, as with any beginner writer, your coding will be sloppy at first, will suffer many stops and starts and strike-throughs and modifications and throwing things into the proverbial trash. With practice, this will become easier and smoother and more effective and more expressive. This workshop is designed to give you an initial push towards that goal. So, let’s start this journey. "],
["a-short-introduction-to-r-objects.html", "1.1 A short introduction to R objects", " 1.1 A short introduction to R objects 1.1.1 Objects The broad categorization of R objects in my mind are functions (verbs) and data objects (nouns). Data objects are in turn of different types: data.frame or tibble: These are rectangular data sets much like you would see in a spreadsheet vector: This is a 1-dimensional list of numbers or strings (words in the language sense), but all must be of the same kind (number or string) matrix: This is a 2-dimensional list of numbers or strings, once again all of the same type A single number or word list: This is a catch-all bucket. Each element of a list can be literally any valid R object. So they could be tibble’s, or functions, or matrices, and different elements can be of different types. Most objects we’ll use in this workshop are going to be data.frame or tibble objects. (In case you’re wondering, they’re basically the same thing, but tibble’s have some modest additional functionality). R comes with a bunch of built-in datasets stored as data.frames. mtcars ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160.0 110 3.90 2.620 16.46 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160.0 110 3.90 2.875 17.02 0 1 4 4 ## Datsun 710 22.8 4 108.0 93 3.85 2.320 18.61 1 1 4 1 ## Hornet 4 Drive 21.4 6 258.0 110 3.08 3.215 19.44 1 0 3 1 ## Hornet Sportabout 18.7 8 360.0 175 3.15 3.440 17.02 0 0 3 2 ## Valiant 18.1 6 225.0 105 2.76 3.460 20.22 1 0 3 1 ## Duster 360 14.3 8 360.0 245 3.21 3.570 15.84 0 0 3 4 ## Merc 240D 24.4 4 146.7 62 3.69 3.190 20.00 1 0 4 2 ## Merc 230 22.8 4 140.8 95 3.92 3.150 22.90 1 0 4 2 ## Merc 280 19.2 6 167.6 123 3.92 3.440 18.30 1 0 4 4 ## Merc 280C 17.8 6 167.6 123 3.92 3.440 18.90 1 0 4 4 ## Merc 450SE 16.4 8 275.8 180 3.07 4.070 17.40 0 0 3 3 ## Merc 450SL 17.3 8 275.8 180 3.07 3.730 17.60 0 0 3 3 ## Merc 450SLC 15.2 8 275.8 180 3.07 3.780 18.00 0 0 3 3 ## Cadillac Fleetwood 10.4 8 472.0 205 2.93 5.250 17.98 0 0 3 4 ## Lincoln Continental 10.4 8 460.0 215 3.00 5.424 17.82 0 0 3 4 ## Chrysler Imperial 14.7 8 440.0 230 3.23 5.345 17.42 0 0 3 4 ## Fiat 128 32.4 4 78.7 66 4.08 2.200 19.47 1 1 4 1 ## Honda Civic 30.4 4 75.7 52 4.93 1.615 18.52 1 1 4 2 ## Toyota Corolla 33.9 4 71.1 65 4.22 1.835 19.90 1 1 4 1 ## Toyota Corona 21.5 4 120.1 97 3.70 2.465 20.01 1 0 3 1 ## Dodge Challenger 15.5 8 318.0 150 2.76 3.520 16.87 0 0 3 2 ## AMC Javelin 15.2 8 304.0 150 3.15 3.435 17.30 0 0 3 2 ## Camaro Z28 13.3 8 350.0 245 3.73 3.840 15.41 0 0 3 4 ## Pontiac Firebird 19.2 8 400.0 175 3.08 3.845 17.05 0 0 3 2 ## Fiat X1-9 27.3 4 79.0 66 4.08 1.935 18.90 1 1 4 1 ## Porsche 914-2 26.0 4 120.3 91 4.43 2.140 16.70 0 1 5 2 ## Lotus Europa 30.4 4 95.1 113 3.77 1.513 16.90 1 1 5 2 ## Ford Pantera L 15.8 8 351.0 264 4.22 3.170 14.50 0 1 5 4 ## Ferrari Dino 19.7 6 145.0 175 3.62 2.770 15.50 0 1 5 6 ## Maserati Bora 15.0 8 301.0 335 3.54 3.570 14.60 0 1 5 8 ## Volvo 142E 21.4 4 121.0 109 4.11 2.780 18.60 1 1 4 2 A data.frame can be acted upon by different functions to help describe it and extract elements from it. For example, to see the size of the data, we use dim(mtcars) ## [1] 32 11 Data sets often have row names and column names. These can be extracted by the functions rownames and colnames or names: rownames(mtcars) ## [1] &quot;Mazda RX4&quot; &quot;Mazda RX4 Wag&quot; &quot;Datsun 710&quot; ## [4] &quot;Hornet 4 Drive&quot; &quot;Hornet Sportabout&quot; &quot;Valiant&quot; ## [7] &quot;Duster 360&quot; &quot;Merc 240D&quot; &quot;Merc 230&quot; ## [10] &quot;Merc 280&quot; &quot;Merc 280C&quot; &quot;Merc 450SE&quot; ## [13] &quot;Merc 450SL&quot; &quot;Merc 450SLC&quot; &quot;Cadillac Fleetwood&quot; ## [16] &quot;Lincoln Continental&quot; &quot;Chrysler Imperial&quot; &quot;Fiat 128&quot; ## [19] &quot;Honda Civic&quot; &quot;Toyota Corolla&quot; &quot;Toyota Corona&quot; ## [22] &quot;Dodge Challenger&quot; &quot;AMC Javelin&quot; &quot;Camaro Z28&quot; ## [25] &quot;Pontiac Firebird&quot; &quot;Fiat X1-9&quot; &quot;Porsche 914-2&quot; ## [28] &quot;Lotus Europa&quot; &quot;Ford Pantera L&quot; &quot;Ferrari Dino&quot; ## [31] &quot;Maserati Bora&quot; &quot;Volvo 142E&quot; names(mtcars) ## [1] &quot;mpg&quot; &quot;cyl&quot; &quot;disp&quot; &quot;hp&quot; &quot;drat&quot; &quot;wt&quot; &quot;qsec&quot; &quot;vs&quot; &quot;am&quot; &quot;gear&quot; ## [11] &quot;carb&quot; Both of these are valid R objects that are vectors of strings. You could save them for future use by assigning them a name using the assignment operator &lt;-. So if you wanted to store the row names, which are the makes and models of the cars in this data set (this structure is not desirable, as we’ll discuss later), you could run car_names &lt;- rownames(mtcars) You can see that this is stored in R for current use, either by typing ls() in the console (for “list”) or by looking in the Environment pane in RStudio. The output of any function is a valid R object, and so you can always store the results of the function by assigning it a name, as above. 1.1.2 Extracting elements from objects We can see the structure of any object by using the function str. str(mtcars) ## &#39;data.frame&#39;: 32 obs. of 11 variables: ## $ mpg : num 21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ... ## $ cyl : num 6 6 4 6 8 6 8 4 4 6 ... ## $ disp: num 160 160 108 258 360 ... ## $ hp : num 110 110 93 110 175 105 245 62 95 123 ... ## $ drat: num 3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ... ## $ wt : num 2.62 2.88 2.32 3.21 3.44 ... ## $ qsec: num 16.5 17 18.6 19.4 17 ... ## $ vs : num 0 0 1 1 0 1 0 1 1 1 ... ## $ am : num 1 1 1 0 0 0 0 0 0 0 ... ## $ gear: num 4 4 4 3 3 3 3 4 4 4 ... ## $ carb: num 4 4 1 1 2 1 4 2 2 4 ... This tells us that mtcars is a data.frame with 32 observations (rows) and 11 variables (columns). Each variable has a name, and all the variables are numeric. data.frame objects are like lists, in that each column can be of a different type. This is a very powerful structure, since we can keep all sorts of data together, and can load spreadsheets with diverse kinds of data easily into R To extract the mpg variable from this data set, there are a few equivalent methods. My preferred method is mtcars[,'mpg'], i.e., extract the column named “mpg” from this data set. Notice that we’re using [] while functions use (). This format of extraction will work when you’re extracting more than one variable, as we’ll see below. Other ways include mtcars[['mpg']] and mtcars$mpg, which are the list way and a data.frame-specific shortcut. You can also extract elements by position, either using the [,] or [[]] forms. So, to extract an element in the 2nd row and 4th column, you’d have to use the matrix notation as mtcars[2,4]. To extract the 4th column, you could use either mtcars[,4] or mtcars[[4]]. To extract the 2nd row, you’d again use the matrix notation as mtcars[2,]. If we want to extract the mpg, cyl and disp variables at once to create a new data.frame, you can use either the matrix notation mtcars[,c('mpg','cyl','disp')] or the list notation mtcars[[c('mpg','cyl','disp')]]. The c() function stands for concatenate and is the function used to create vectors. We’ll actually see a much more user-friendly way of doing this in the data munging section (Chapter 4). Advanced note: A data.frame object is really a list object where all the elements are vectors of the same length, and which happen to have names assigned to them. The object also looks like a matrix or 2-dimensional array visually. So both notations were allowed to be valid for data.frame objects. "],
["r-packages.html", "1.2 R Packages", " 1.2 R Packages Packages are modules of R code that enhance the capabilities of R. Many packages are well established and curated, and have to go through a strict software compatibility review before allowed on CRAN. Installing packages Installing packages on your computer can be done from the RStudio menu (Tools &gt; Install Packages), or by running the command install.packages(&lt;package name&gt;, repos = &quot;https://cran.rstudio.com&quot;). For example, to install the readxl package, which we will use shortly, we would run the code install.packages(&quot;readxl&quot;, repos=&quot;https://cran.rstudio.com&quot;) You can set the default repository in RStudio, in Tools &gt; Global Options. Be aware that everything here is case-sensitive Another way to install packages is to go to the Packages pane in RStudio, use the search bar there to find the package you want to install, and then click the checkbox beside the name. This is convenient, but not very reproducible if you have to move to a different computer, so it’s generally discouraged. How do you find packages? Glad you asked. The easiest way to find packages on CRAN is actually through the RStudio Packages pane, where the entire set of available packages are listed with a brief, top-line description. You can click on the package name to see a much more detailed overview of the packages, and many packages do have vignettes which give more information. However, once you’ve found the package you want, you should really code it up with install.packages, so that you can save the script for later when you might need to remember it again. 1.2.1 Loading packages in R We will use several packages to enhance our experience and get going faster. However, to use a package, you must first load it into R. To load a package into R, you use the function library (ironically). The first package we will load is the tidyverse package. This is actually a meta-package, which in turn loads a bunch of other packages. These form a core group of useful packages that are widely used, including readr (reading data from text files) tidyr (Manipulation, pivoting) dplyr (summarize, aggregate, filter) ggplot2 (visualization) purrr (functions applied across data structures, meta-programming) stringr (string manipulation) forcats (categorical data) In addition, we’ll load the readxl package for reading Excel files. library(tidyverse) library(readxl) "],
["r-resources.html", "1.3 R Resources", " 1.3 R Resources There are many high quality resources for learning R available online. This is a selection of what I find most useful. CRAN Task Views: These are curated lists of R packages for various purposes, ranging from econometrics to mathematics, finance, imaging, social sciences, time series, spatial analyses and more. RStudio Cheatsheets: These are high-quality cheatsheets about different aspects of the R analytic pipeline. StackOverflow #r: The r tag on StackOverflow is the place to find answers about R Twitter #rstats: The who’s who of R hang out at the #rstats hashtag, and questions can get answered very quickly. Also a way to find out what new packages are coming up R-Bloggers: A blog aggregator which collects a few hundred R-related blogs in one place (including mine, in the interests of disclosure) RSeek: When one realizes that R is just a letter in the alphabet, Google searches can be a bit difficult. RSeek has created a custom search targeted at R-related topics, sites and packages on the web. "],
["rstudio-your-development-environment-authoring-program.html", "Chapter 2 RStudio, your development environment (authoring program)", " Chapter 2 RStudio, your development environment (authoring program) While R is the language we will learn, RStudio is the interface (or integrated development environment) we will use to write it, interact with it, and see our results. RStudio provides by far the most user-friendly interface to R (though it’s not point-and-click). This is the “journal” or “notebook” in which you will start your writing journey in R "],
["starting-rstudio.html", "Starting RStudio", " Starting RStudio When you open RStudio, either from your desktop or from the Start menu, you’ll see something like this: I’ll note that I’ve done some customization to my console, which you can also do by going to Tools &gt; Global Options. Your screen will most likely have a white rather than a dark background You can open a new panel for an R script using either File &gt; New File &gt; R Script or using the button at the top left of the window: This opens up an R script file that you can edit and save. You will mainly be writing in this panel within a R script (see 2.1 for more details). You will also have a Console panel where the code will actually run in R. "],
["other-panes.html", "Other panes", " Other panes There are several other panes in RStudio that we will see in due course. Environment: This shows all the objects (“words”) in your current environment History: This gives a history of the commands you have run. This is searchable. Though you do have a stored history, see 2.1 for why you shouldn’t fall to temptation to just code in the console. Files: This is exactly like File Explorer in Windows, and lets you see the contents of a folder/directory Plot: These is where the plots will show up. See ?? for more details on how to create plots Packages: This gives a listing of installed packages. You can click on the tick boxes to load packages into your environment, but I prefer coding it in (see section ??) to make it reproducible and verifiable. Help: This will show help files once they are evoked Viewer: This pane shows results when they are produced as HTML documents. This pane will also come into play once we start with interactive visualizations in section 9.10. Feel free to explore these different panes and understand their functionalities. "],
["workflow.html", "2.1 Rstudio workflow", " 2.1 Rstudio workflow As we’ve seen, RStudio has both a scripting pane to write code, and a console pane to run code. Of course, you can write code directly into the console, but it is not a good practice. You will tend to get sloppy, lose the “story”, and generally have less reproducible code. Writing the program (“story”) is just more reliable if you write into the script file and the send it to the console to run. Sending it to the console can be acheieved with a keyboard shortcut, Ctrl-Enter (or Cmd-Enter on a Mac). This is something that will be second nature while coding in RStudio. When you write code, be sure to comment your code liberally. In R, any line or any phrase starting with # is considered a comment and is ignored by the program. This allows you to comment your code, explain your ideas to yourself and generally make your code more readable. To further this goal, write your code in differnt lines, and indent, to make it more readable; R ignores white space in your file. Why bother doing this? Basically because the most likely next person to see your code is going to be you in 6 months, and you don’t want to be scratching your head wondering what you were doing earlier (been there, done that, don’t like it). You certainly can’t phone your earlier self, so the best strategy is to write comments for your future self to minimize future grief. "],
["rstudio-projects.html", "2.2 RStudio Projects", " 2.2 RStudio Projects Projects are a nice way to organize your data projects within RStudio. Projects keep together input data, R scripts, analytical results, and figures, and keeps different projects separate. Each project can run on its own independent R session (no worries about cross-hybridization), and you can have several projects open concurrently without risk of cross-pollinating them. To make a new project, click File &gt; New Project, then: Note that I always create a git repository for version control. If you’re not doing that, untick the box in the window above. "],
["loading-data-into-r.html", "Chapter 3 Loading data into R", " Chapter 3 Loading data into R R can access data files from a wide variety of sources. These include Text files (csv, tsv, fixed-width) Microsoft Excel files Microsoft Access databases SQL-based databases (MySql, Postgresql, SQLite, Amazon Redshift) Enterprise databases (SAP, Oracle) The R package rio can help read and write to many file types that are single files, and the package rodbc can do the same for the databases. Exercise: Install the R package rio into your R installation install.packages(&quot;rio&quot;, repos = &quot;https://cran.rstudio.com&quot;) # Note the quotes The rio package has a common way of reading data (using the import function). Importing the data will create an object called a data.frame, but if you just import data, it is not saved since it doesn’t yet have a name. library(rio) # activate the package import(&#39;data/HR_Data.csv&#39;) # can use single or double quotes So every time you import data, you have to name it. You do this using the &lt;- operator. hr_data &lt;- import(&#39;data/HR_Data.csv&#39;) Now, if you type hr_data in the console, you will see the data you imported. head(hr_data) # This just displays the first 10 lines of the data ## Bureau Gender Grade ## 1 Comptroller and Global Financial Services (CGFS) female N/A ## 2 East Asian and Pacific Affairs (EAP) female N/A ## 3 Overseas Buildings Operations (OBO) male FS-5 ## 4 Conflict and Stabilization Operations (CSO) male N/A ## 5 Consular Affairs (CA) female FS-5 ## 6 Management Policy, Rightsizing and Innovation (PRI) female FS-2 ## Name ## 1 Katrina Lilly ## 2 Keene ## 3 Garrett Murphy ## 4 Jim Rhodes ## 5 Anita Myers ## 6 Vivian Einhorn ## Skills ## 1 Hydrology, Research, Design, human resources, Administration ## 2 Sharepoint, Planning ## 3 interagency, Portuguese, Management, Foreign Policy, Economics, Human Resources ## 4 education, seo, German, Finance, design, portuguese, disease response, Excel ## 5 Healthcare, training, German, french, Sharepoint, Marketing, Data Analysis, Economics, spanish ## 6 data analysis, Web Development, Hydrology, IT, SEO, Disease Response, Japanese ## YearsService ## 1 16 ## 2 21 ## 3 5 ## 4 4 ## 5 23 ## 6 19 Seeing the data like this is certainly a bit awkward, especially for large datasets. In RStudio, you can see the data somewhat like a spreadsheet with the following command: View(hr_data) This results in a new pane in RStudio. "],
["finer-control-of-csv-imports.html", "3.1 Finer control of CSV imports", " 3.1 Finer control of CSV imports We can provide finer control over importing text files using additional options (“adverbs”) to the import function (“verb”). For example, it might be good to check if all the column names are unique, and to make them not have spaces (which are awkward in terms of typing and functionality). You can add the option check.names = TRUE to the command: hr_data &lt;- import(&#39;data/HR_Data.csv&#39;, check.names = TRUE) Similarly, if you’re using European data, where the decimal point is denoted by a comma, you can add the following option: hr_data &lt;- import(&#39;data/HR_Data.csv&#39;, check.names = TRUE, dec = &#39;,&#39;) You can see most of the options in the help file for import, which you can access either from the Help pane, or by typing ?import or help(import) in the console "],
["finer-control-of-excel-imports.html", "3.2 Finer control of Excel imports", " 3.2 Finer control of Excel imports You can specify sheet names or sheet positions for import from an Excel file. If you know the sheet name, you can specify it using the which option: dos_data &lt;- import(&#39;data/simulatedDOS.xlsx&#39;, which=&#39;Staffing_by_Bureau&#39;) You can also grab the same sheet by position: dos_data &lt;- import(&#39;data/simulatedDOS.xlsx&#39;, which = 2) We’ll talk about how to grab multiple sheets together into a list in the data munging section4. "],
["importing-data-from-databases.html", "3.3 Importing data from databases", " 3.3 Importing data from databases If you have data in an Access database, you can read it in pretty easily using the RODBC package. To import one particular table from Access, you can use library(RODBC) # activate package, case-sensitive channel &lt;- odbcConnectAccess(&#39;C:/Documents/Name_of_Access_Database&#39;) # change to your mydata &lt;- sqlQuery(channel, paste(&quot;select * from Name_of_table_in_database&quot;)) For other databases, the connection can be made using the odbc package. You can connnect to a MySQL database, for example, using library(odbc) con &lt;- dbConnect(odbc(), Driver = &quot;[your driver&#39;s name]&quot;, Server = &quot;[your server&#39;s path]&quot;, Database = &quot;[your database&#39;s name]&quot;, UID = rstudioapi::askForPassword(&quot;Database user&quot;), PWD = rstudioapi::askForPassword(&quot;Database password&quot;), Port = 1433) and you can load a table into R using dat &lt;- dbGetQuery(con, &#39;select * from &lt;table name&gt;&#39;) You’ll notice that it is a bit more complicated to call data from databases, though once it’s set up, it works beautifully. For more details about this process for different databases, see RStudio’s tutorial. "],
["sec-data-munging.html", "Chapter 4 Data Munging", " Chapter 4 Data Munging Data munging refers to the work of transforming data to make it usable for a computer. Data unfortunately comes in all shapes and sizes, with all sorts of issues, so this process can take a while. Often a rule of thumb is that making a data set ready for analysis takes about 80% of the time of a project. "],
["tidy-data.html", "4.1 Tidy data", " 4.1 Tidy data There is a principle of making data “tidy”, promoted by Dr. Hadley Wickham. This tidying of data makes computer programs happy, since these data can be most easily digested. A dataset can be messy or tidy depending on how the rows, columns and tables you’re using align with observations, variables and types. The properties of a tidy dataset are: Each variable forms a column Each observation forms a row Each type of observational unit forms a table. This forms a standardized way to structure a dataset, and so makes it easy for the analyst to develop standard pipelines. A dataset can be messy in many many ways. Many of the more common issues are listed below: Column names contain values, not just variable names Multiple variables are stored in one column Variables are stored in both rows and columns Multiple types of observational types are stored in the same table A single observational unit is stored in multiple tables Sometimes the messier format is better for data entry, but bad for data analyses. We’ll show a few examples here, but a more detailed discussion is available online. The workhorse for this tidying activity is the tidyr package, part of the tidyverse meta-package. We’ll tend to start every analysis by loading the tidyverse package, so we are covered. 4.1.1 Variable in column names library(tidyverse) pew &lt;- import(&#39;data/pew.csv&#39;) head(pew) ## religion &lt;$10k $10-20k $20-30k $30-40k $40-50k $50-75k ## 1 Agnostic 27 34 60 81 76 137 ## 2 Atheist 12 27 37 52 35 70 ## 3 Buddhist 27 21 30 34 33 58 ## 4 Catholic 418 617 732 670 638 1116 ## 5 Don’t know/refused 15 14 15 11 10 35 ## 6 Evangelical Prot 575 869 1064 982 881 1486 ## $75-100k $100-150k &gt;150k Don&#39;t know/refused ## 1 122 109 84 96 ## 2 73 59 74 76 ## 3 62 39 53 54 ## 4 949 792 633 1489 ## 5 21 17 18 116 ## 6 949 723 414 1529 This dataset has actual data in the column headers, rather than variable names. This information needs to be captured into a column. We should ideally have 3 columns in this dataset: religion, income and frequency. We can achieve this using a function called gather which takes a wide dataset and makes it tall. We will do this by forming a pipeline (think of this as a sentence), starting with the dataset. pew %&gt;% gather(income, frequency, -religion) ## religion income frequency ## 1 Agnostic &lt;$10k 27 ## 2 Atheist &lt;$10k 12 ## 3 Buddhist &lt;$10k 27 ## 4 Catholic &lt;$10k 418 ## 5 Don’t know/refused &lt;$10k 15 ## 6 Evangelical Prot &lt;$10k 575 ## 7 Hindu &lt;$10k 1 ## 8 Historically Black Prot &lt;$10k 228 ## 9 Jehovah&#39;s Witness &lt;$10k 20 ## 10 Jewish &lt;$10k 19 ## 11 Mainline Prot &lt;$10k 289 ## 12 Mormon &lt;$10k 29 ## 13 Muslim &lt;$10k 6 ## 14 Orthodox &lt;$10k 13 ## 15 Other Christian &lt;$10k 9 ## 16 Other Faiths &lt;$10k 20 ## 17 Other World Religions &lt;$10k 5 ## 18 Unaffiliated &lt;$10k 217 ## 19 Agnostic $10-20k 34 ## 20 Atheist $10-20k 27 ## 21 Buddhist $10-20k 21 ## 22 Catholic $10-20k 617 ## 23 Don’t know/refused $10-20k 14 ## 24 Evangelical Prot $10-20k 869 ## 25 Hindu $10-20k 9 ## 26 Historically Black Prot $10-20k 244 ## 27 Jehovah&#39;s Witness $10-20k 27 ## 28 Jewish $10-20k 19 ## 29 Mainline Prot $10-20k 495 ## 30 Mormon $10-20k 40 ## 31 Muslim $10-20k 7 ## 32 Orthodox $10-20k 17 ## 33 Other Christian $10-20k 7 ## 34 Other Faiths $10-20k 33 ## 35 Other World Religions $10-20k 2 ## 36 Unaffiliated $10-20k 299 ## 37 Agnostic $20-30k 60 ## 38 Atheist $20-30k 37 ## 39 Buddhist $20-30k 30 ## 40 Catholic $20-30k 732 ## 41 Don’t know/refused $20-30k 15 ## 42 Evangelical Prot $20-30k 1064 ## 43 Hindu $20-30k 7 ## 44 Historically Black Prot $20-30k 236 ## 45 Jehovah&#39;s Witness $20-30k 24 ## 46 Jewish $20-30k 25 ## 47 Mainline Prot $20-30k 619 ## 48 Mormon $20-30k 48 ## 49 Muslim $20-30k 9 ## 50 Orthodox $20-30k 23 ## 51 Other Christian $20-30k 11 ## 52 Other Faiths $20-30k 40 ## 53 Other World Religions $20-30k 3 ## 54 Unaffiliated $20-30k 374 ## 55 Agnostic $30-40k 81 ## 56 Atheist $30-40k 52 ## 57 Buddhist $30-40k 34 ## 58 Catholic $30-40k 670 ## 59 Don’t know/refused $30-40k 11 ## 60 Evangelical Prot $30-40k 982 ## 61 Hindu $30-40k 9 ## 62 Historically Black Prot $30-40k 238 ## 63 Jehovah&#39;s Witness $30-40k 24 ## 64 Jewish $30-40k 25 ## 65 Mainline Prot $30-40k 655 ## 66 Mormon $30-40k 51 ## 67 Muslim $30-40k 10 ## 68 Orthodox $30-40k 32 ## 69 Other Christian $30-40k 13 ## 70 Other Faiths $30-40k 46 ## 71 Other World Religions $30-40k 4 ## 72 Unaffiliated $30-40k 365 ## 73 Agnostic $40-50k 76 ## 74 Atheist $40-50k 35 ## 75 Buddhist $40-50k 33 ## 76 Catholic $40-50k 638 ## 77 Don’t know/refused $40-50k 10 ## 78 Evangelical Prot $40-50k 881 ## 79 Hindu $40-50k 11 ## 80 Historically Black Prot $40-50k 197 ## 81 Jehovah&#39;s Witness $40-50k 21 ## 82 Jewish $40-50k 30 ## 83 Mainline Prot $40-50k 651 ## 84 Mormon $40-50k 56 ## 85 Muslim $40-50k 9 ## 86 Orthodox $40-50k 32 ## 87 Other Christian $40-50k 13 ## 88 Other Faiths $40-50k 49 ## 89 Other World Religions $40-50k 2 ## 90 Unaffiliated $40-50k 341 ## 91 Agnostic $50-75k 137 ## 92 Atheist $50-75k 70 ## 93 Buddhist $50-75k 58 ## 94 Catholic $50-75k 1116 ## 95 Don’t know/refused $50-75k 35 ## 96 Evangelical Prot $50-75k 1486 ## 97 Hindu $50-75k 34 ## 98 Historically Black Prot $50-75k 223 ## 99 Jehovah&#39;s Witness $50-75k 30 ## 100 Jewish $50-75k 95 ## 101 Mainline Prot $50-75k 1107 ## 102 Mormon $50-75k 112 ## 103 Muslim $50-75k 23 ## 104 Orthodox $50-75k 47 ## 105 Other Christian $50-75k 14 ## 106 Other Faiths $50-75k 63 ## 107 Other World Religions $50-75k 7 ## 108 Unaffiliated $50-75k 528 ## 109 Agnostic $75-100k 122 ## 110 Atheist $75-100k 73 ## 111 Buddhist $75-100k 62 ## 112 Catholic $75-100k 949 ## 113 Don’t know/refused $75-100k 21 ## 114 Evangelical Prot $75-100k 949 ## 115 Hindu $75-100k 47 ## 116 Historically Black Prot $75-100k 131 ## 117 Jehovah&#39;s Witness $75-100k 15 ## 118 Jewish $75-100k 69 ## 119 Mainline Prot $75-100k 939 ## 120 Mormon $75-100k 85 ## 121 Muslim $75-100k 16 ## 122 Orthodox $75-100k 38 ## 123 Other Christian $75-100k 18 ## 124 Other Faiths $75-100k 46 ## 125 Other World Religions $75-100k 3 ## 126 Unaffiliated $75-100k 407 ## 127 Agnostic $100-150k 109 ## 128 Atheist $100-150k 59 ## 129 Buddhist $100-150k 39 ## 130 Catholic $100-150k 792 ## 131 Don’t know/refused $100-150k 17 ## 132 Evangelical Prot $100-150k 723 ## 133 Hindu $100-150k 48 ## 134 Historically Black Prot $100-150k 81 ## 135 Jehovah&#39;s Witness $100-150k 11 ## 136 Jewish $100-150k 87 ## 137 Mainline Prot $100-150k 753 ## 138 Mormon $100-150k 49 ## 139 Muslim $100-150k 8 ## 140 Orthodox $100-150k 42 ## 141 Other Christian $100-150k 14 ## 142 Other Faiths $100-150k 40 ## 143 Other World Religions $100-150k 4 ## 144 Unaffiliated $100-150k 321 ## 145 Agnostic &gt;150k 84 ## 146 Atheist &gt;150k 74 ## 147 Buddhist &gt;150k 53 ## 148 Catholic &gt;150k 633 ## 149 Don’t know/refused &gt;150k 18 ## 150 Evangelical Prot &gt;150k 414 ## 151 Hindu &gt;150k 54 ## 152 Historically Black Prot &gt;150k 78 ## 153 Jehovah&#39;s Witness &gt;150k 6 ## 154 Jewish &gt;150k 151 ## 155 Mainline Prot &gt;150k 634 ## 156 Mormon &gt;150k 42 ## 157 Muslim &gt;150k 6 ## 158 Orthodox &gt;150k 46 ## 159 Other Christian &gt;150k 12 ## 160 Other Faiths &gt;150k 41 ## 161 Other World Religions &gt;150k 4 ## 162 Unaffiliated &gt;150k 258 ## 163 Agnostic Don&#39;t know/refused 96 ## 164 Atheist Don&#39;t know/refused 76 ## 165 Buddhist Don&#39;t know/refused 54 ## 166 Catholic Don&#39;t know/refused 1489 ## 167 Don’t know/refused Don&#39;t know/refused 116 ## 168 Evangelical Prot Don&#39;t know/refused 1529 ## 169 Hindu Don&#39;t know/refused 37 ## 170 Historically Black Prot Don&#39;t know/refused 339 ## 171 Jehovah&#39;s Witness Don&#39;t know/refused 37 ## 172 Jewish Don&#39;t know/refused 162 ## 173 Mainline Prot Don&#39;t know/refused 1328 ## 174 Mormon Don&#39;t know/refused 69 ## 175 Muslim Don&#39;t know/refused 22 ## 176 Orthodox Don&#39;t know/refused 73 ## 177 Other Christian Don&#39;t know/refused 18 ## 178 Other Faiths Don&#39;t know/refused 71 ## 179 Other World Religions Don&#39;t know/refused 8 ## 180 Unaffiliated Don&#39;t know/refused 597 Let’s parse this out. First we see this new operator %&gt;%, which you can think of as the word “then”. So we start with the dataset pew, “then” we gather its columns into two columns, income and frequency. We don’t want the religion column to be part of this operation, so we “minus” it out, which says, don’t do this gather operation on the religion column, but use everything else. The religion column gets repeated as needed. The %&gt;% operator can be easily typed in RStudio using the shortcut Ctrl-Shift-M (Cmd-Shift-M on a Mac) This is now a tidy dataset, since each column is a single variable, each row is a single observation 4.1.2 Multiple variables in column names tb &lt;- import(&#39;data/tb.csv&#39;) %&gt;% as_tibble() head(tb) ## # A tibble: 6 x 22 ## iso2 year m04 m514 m014 m1524 m2534 m3544 m4554 m5564 m65 mu ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 AD 1989 NA NA NA NA NA NA NA NA NA NA ## 2 AD 1990 NA NA NA NA NA NA NA NA NA NA ## 3 AD 1991 NA NA NA NA NA NA NA NA NA NA ## 4 AD 1992 NA NA NA NA NA NA NA NA NA NA ## 5 AD 1993 NA NA NA NA NA NA NA NA NA NA ## 6 AD 1994 NA NA NA NA NA NA NA NA NA NA ## # … with 10 more variables: f04 &lt;int&gt;, f514 &lt;int&gt;, f014 &lt;int&gt;, ## # f1524 &lt;int&gt;, f2534 &lt;int&gt;, f3544 &lt;int&gt;, f4554 &lt;int&gt;, f5564 &lt;int&gt;, ## # f65 &lt;int&gt;, fu &lt;int&gt; Notice that the column names contain both sex and age group data. First we’ll gather the sex/age columns, as before. Note that there are many missing values in this dataset. These are denoted in R by NA. tb %&gt;% gather(sex_age, n, -iso2, -year, -fu) ## # A tibble: 109,611 x 5 ## iso2 year fu sex_age n ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; ## 1 AD 1989 NA m04 NA ## 2 AD 1990 NA m04 NA ## 3 AD 1991 NA m04 NA ## 4 AD 1992 NA m04 NA ## 5 AD 1993 NA m04 NA ## 6 AD 1994 NA m04 NA ## 7 AD 1996 NA m04 NA ## 8 AD 1997 NA m04 NA ## 9 AD 1998 NA m04 NA ## 10 AD 1999 NA m04 NA ## # … with 109,601 more rows Since there are a lot of missing values here, we can drop them in the above step by adding an option. tb %&gt;% gather(sex_age, n, -iso2, -year, -fu, na.rm=T) ## # A tibble: 35,478 x 5 ## iso2 year fu sex_age n ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; ## 1 AD 2005 0 m04 0 ## 2 AD 2006 0 m04 0 ## 3 AD 2008 0 m04 0 ## 4 AE 2006 NA m04 0 ## 5 AE 2007 NA m04 0 ## 6 AE 2008 0 m04 0 ## 7 AG 2007 NA m04 0 ## 8 AL 2005 0 m04 0 ## 9 AL 2006 0 m04 1 ## 10 AL 2007 0 m04 0 ## # … with 35,468 more rows We can now use the function separate to separate the data in the sex_age column into sex and age. In this case we have have the data in a fixed width format (the 1st element is the sex data), so we can use that: tb %&gt;% gather(sex_age, n, -iso2, -year, -fu, na.rm=T) %&gt;% separate(sex_age, c(&quot;sex&quot;,&quot;age&quot;), sep=1) ## # A tibble: 35,478 x 6 ## iso2 year fu sex age n ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 AD 2005 0 m 04 0 ## 2 AD 2006 0 m 04 0 ## 3 AD 2008 0 m 04 0 ## 4 AE 2006 NA m 04 0 ## 5 AE 2007 NA m 04 0 ## 6 AE 2008 0 m 04 0 ## 7 AG 2007 NA m 04 0 ## 8 AL 2005 0 m 04 0 ## 9 AL 2006 0 m 04 1 ## 10 AL 2007 0 m 04 0 ## # … with 35,468 more rows If the data was separated by a symbol, like _, we would use sep = &quot;_&quot; instead. 4.1.3 Variables stored in rows and columns weather &lt;- import(&#39;data/weather.csv&#39;) %&gt;% as_tibble() weather ## # A tibble: 22 x 35 ## id year month element d1 d2 d3 d4 d5 d6 d7 ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 MX17… 2010 1 tmax NA NA NA NA NA NA NA ## 2 MX17… 2010 1 tmin NA NA NA NA NA NA NA ## 3 MX17… 2010 2 tmax NA 27.3 24.1 NA NA NA NA ## 4 MX17… 2010 2 tmin NA 14.4 14.4 NA NA NA NA ## 5 MX17… 2010 3 tmax NA NA NA NA 32.1 NA NA ## 6 MX17… 2010 3 tmin NA NA NA NA 14.2 NA NA ## 7 MX17… 2010 4 tmax NA NA NA NA NA NA NA ## 8 MX17… 2010 4 tmin NA NA NA NA NA NA NA ## 9 MX17… 2010 5 tmax NA NA NA NA NA NA NA ## 10 MX17… 2010 5 tmin NA NA NA NA NA NA NA ## # … with 12 more rows, and 24 more variables: d8 &lt;dbl&gt;, d9 &lt;lgl&gt;, ## # d10 &lt;dbl&gt;, d11 &lt;dbl&gt;, d12 &lt;lgl&gt;, d13 &lt;dbl&gt;, d14 &lt;dbl&gt;, d15 &lt;dbl&gt;, ## # d16 &lt;dbl&gt;, d17 &lt;dbl&gt;, d18 &lt;lgl&gt;, d19 &lt;lgl&gt;, d20 &lt;lgl&gt;, d21 &lt;lgl&gt;, ## # d22 &lt;lgl&gt;, d23 &lt;dbl&gt;, d24 &lt;lgl&gt;, d25 &lt;dbl&gt;, d26 &lt;dbl&gt;, d27 &lt;dbl&gt;, ## # d28 &lt;dbl&gt;, d29 &lt;dbl&gt;, d30 &lt;dbl&gt;, d31 &lt;dbl&gt; Here, for each year and month, the data for each day of the month is stored in columns. For each day, two values are noted – the max (tmax) and min (tmin) temperature that day, stored as rows. We start by gathering the extra columns as before: weather %&gt;% gather(day, temp, d1:d31) ## # A tibble: 682 x 6 ## id year month element day temp ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 MX17004 2010 1 tmax d1 NA ## 2 MX17004 2010 1 tmin d1 NA ## 3 MX17004 2010 2 tmax d1 NA ## 4 MX17004 2010 2 tmin d1 NA ## 5 MX17004 2010 3 tmax d1 NA ## 6 MX17004 2010 3 tmin d1 NA ## 7 MX17004 2010 4 tmax d1 NA ## 8 MX17004 2010 4 tmin d1 NA ## 9 MX17004 2010 5 tmax d1 NA ## 10 MX17004 2010 5 tmin d1 NA ## # … with 672 more rows Here’s a new notation – d1:d31. This means all columns starting at d1 and ending at d31. This notation is originally from creating sequences of numbers. See what happens if you type 1:30 in the console. Now, for each date, we have two rows of data. These need to be two columns of data. So we need to do the reverse operation from gather. This is called spread. weather %&gt;% gather(date, temp, d1:d31) %&gt;% spread(element, temp) ## # A tibble: 341 x 6 ## id year month date tmax tmin ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 MX17004 2010 1 d1 NA NA ## 2 MX17004 2010 1 d10 NA NA ## 3 MX17004 2010 1 d11 NA NA ## 4 MX17004 2010 1 d12 NA NA ## 5 MX17004 2010 1 d13 NA NA ## 6 MX17004 2010 1 d14 NA NA ## 7 MX17004 2010 1 d15 NA NA ## 8 MX17004 2010 1 d16 NA NA ## 9 MX17004 2010 1 d17 NA NA ## 10 MX17004 2010 1 d18 NA NA ## # … with 331 more rows We tell spread which column should form column names and which should provide the data for the columns. "],
["data-cleaning.html", "4.2 Data cleaning", " 4.2 Data cleaning The weather data set shows that we still need to do a bit more cleaning to this data to make it workable. Mainly, we need to fix the dat column to make it numeric. Note the odd ordering, where d1 is followed by d10. This is an alphabetical ordering rather than a numeric ordering. We’ll now add to our pipeline (sentence) to make this happen: weather %&gt;% gather(date, temp, d1:d31) %&gt;% spread(element, temp) %&gt;% mutate(date = parse_number(date)) ## # A tibble: 341 x 6 ## id year month date tmax tmin ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 MX17004 2010 1 1 NA NA ## 2 MX17004 2010 1 10 NA NA ## 3 MX17004 2010 1 11 NA NA ## 4 MX17004 2010 1 12 NA NA ## 5 MX17004 2010 1 13 NA NA ## 6 MX17004 2010 1 14 NA NA ## 7 MX17004 2010 1 15 NA NA ## 8 MX17004 2010 1 16 NA NA ## 9 MX17004 2010 1 17 NA NA ## 10 MX17004 2010 1 18 NA NA ## # … with 331 more rows Here we introduce another “verb”, mutate. This function changes a column, either in-place as we did here, or by creating a new variable. The data is still not quite in the right format, since the date column is in a weird order. We can add another verb to this pipe to fix that: arrange. weather %&gt;% gather(date, temp, d1:d31) %&gt;% spread(element, temp) %&gt;% mutate(date = parse_number(date)) %&gt;% arrange(date) ## # A tibble: 341 x 6 ## id year month date tmax tmin ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 MX17004 2010 1 1 NA NA ## 2 MX17004 2010 2 1 NA NA ## 3 MX17004 2010 3 1 NA NA ## 4 MX17004 2010 4 1 NA NA ## 5 MX17004 2010 5 1 NA NA ## 6 MX17004 2010 6 1 NA NA ## 7 MX17004 2010 7 1 NA NA ## 8 MX17004 2010 8 1 NA NA ## 9 MX17004 2010 10 1 NA NA ## 10 MX17004 2010 11 1 NA NA ## # … with 331 more rows Not quite, right? We’re not used to seeing all the 1st of the months together, and so forth. We want all the daes for month 1, then all the dates for month two, and so on. This can be done by modifying the arrange command, by sorting first by month and then by date (essentially within month). weather %&gt;% gather(date, temp, d1:d31) %&gt;% spread(element, temp) %&gt;% mutate(date = parse_number(date)) %&gt;% arrange(month, date) ## # A tibble: 341 x 6 ## id year month date tmax tmin ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 MX17004 2010 1 1 NA NA ## 2 MX17004 2010 1 2 NA NA ## 3 MX17004 2010 1 3 NA NA ## 4 MX17004 2010 1 4 NA NA ## 5 MX17004 2010 1 5 NA NA ## 6 MX17004 2010 1 6 NA NA ## 7 MX17004 2010 1 7 NA NA ## 8 MX17004 2010 1 8 NA NA ## 9 MX17004 2010 1 9 NA NA ## 10 MX17004 2010 1 10 NA NA ## # … with 331 more rows Finally, if we want to save this, we need to assign this final product a name. weather2 &lt;- weather %&gt;% gather(date, temp, d1:d31) %&gt;% spread(element, temp) %&gt;% mutate(date = parse_number(date)) %&gt;% arrange(month, date) Exercise The file data/mbta.xlsx contains monthly data on number of commuter trips by different modalities on the MBTA system n Boston. It is in a messy format. It also has an additional quirk in that it has a title on the first line that isn’t even data. You can avoid loading that in by using the option skip=1 (i.e. skip the first line) when you import. Work through this process to clean this dataset into tidy form. I’ll also note that you can “minus” columns by position as well as name, so gather(date, avg_trips, -1, -mode) is valid to not involve the first column and the mode column. "],
["cleaning-up-data-types-and-values.html", "4.3 Cleaning up data types and values", " 4.3 Cleaning up data types and values After you have tidied your data, lets call that tidy dataset mbta2. mbta2 ## # A tibble: 638 x 5 ## ..1 mode year month avg_trips ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 All Modes by Qtr 2007 01 NA ## 2 2 Boat 2007 01 4 ## 3 3 Bus 2007 01 335.819 ## 4 4 Commuter Rail 2007 01 142.2 ## 5 5 Heavy Rail 2007 01 435.294 ## 6 6 Light Rail 2007 01 227.231 ## 7 7 Pct Chg / Yr 2007 01 0.02 ## 8 8 Private Bus 2007 01 4.772 ## 9 9 RIDE 2007 01 4.9 ## 10 10 Trackless Trolley 2007 01 12.757 ## # … with 628 more rows We see that there’s still some issues. If you look at the top of the dataset, you’ll see that year, month and avg_trips are all character variables and not numeric variables. (You can see this if you converted to a tibble using as_tibble. Otherwise, type str(mbta2) at the console). Also, there is this odd column with the name ..1 that is just an index of rows. Lastly, the row marked TOTAL is not necessary since it’s a derived row, and the All Modes by Qtr row is missing in many times, and appears inconsistent with TOTAL. First, let’s deal with the type issue. A more advanced version of this operation would be mbta2 %&gt;% mutate_at(vars(year, month, avg_trips), parse_number) Next we want to get rid of that first column. The verb we’ll use here is select. mbta2 %&gt;% mutate( year = parse_number(year), month = parse_number(month), avg_trips = parse_number(avg_trips) ) %&gt;% select(-1) # Get rid of 1st column ## # A tibble: 638 x 4 ## mode year month avg_trips ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 All Modes by Qtr 2007 1 NA ## 2 Boat 2007 1 4 ## 3 Bus 2007 1 336. ## 4 Commuter Rail 2007 1 142. ## 5 Heavy Rail 2007 1 435. ## 6 Light Rail 2007 1 227. ## 7 Pct Chg / Yr 2007 1 0.02 ## 8 Private Bus 2007 1 4.77 ## 9 RIDE 2007 1 4.9 ## 10 Trackless Trolley 2007 1 12.8 ## # … with 628 more rows Lastly, we want to get rid of rows where mode equals TOTAL or “All Modes by Qtr”. Our verb here is filter. mbta3 &lt;- mbta2 %&gt;% mutate( year = parse_number(year), month = parse_number(month), avg_trips = parse_number(avg_trips) ) %&gt;% select(-1) %&gt;% filter(mode != &#39;TOTAL&#39;, mode != &quot;All Modes by Qtr&quot;) Note that the strings in quotes have to be exact matches to what you want to look for. The != means “not equals”. We’re assigning this to a new variable, mbta3, which is our clean dataset. In R, filtering refers to keeping or removing rows that meet some criterion; selecting refers to keeping or removing columns. The corresponding “verbs” to put into your pipeline are filter and select. "],
["other-types-of-cleaning.html", "4.4 Other types of cleaning", " 4.4 Other types of cleaning There are different functions that you can apply to a dataset for different cleaning purposes. A selection are given below: distinct() keeps the unique (non-duplicate) rows of a dataset. Usage: dataset %&gt;% distinct() If you want to keep only rows with complete data, you can invoke drop_na. Usage: dataset %&gt;% drop_na(). You can modify drop_na by specifying variables from which you want to drop the missing values. If you want to convert a value to missing (commonly 99 is used for missing data), then you can use replace_na within mutate to change to missing values on a column-by-column basis. Usage: dataset %&gt;% mutate(var1 = na_if(var1, 99)) "],
["cleaning-from-excel-files.html", "4.5 Cleaning from Excel files", " 4.5 Cleaning from Excel files Excel, being omnipresent, creates its own sets of difficulties. Excel, on top of being a data entry and analysis platform, is also a visual platform, so tables are often created to look good rather than be tidy. Things we commonly find in Excel files include colored rows and columns, multiple lines of headers, multiple rows with variables, typos resulting in numeric data becoming string data, and many others. Let’s start with a data set that’s structured similarly to many government datasets around the world. Notice that there are two levels of headers on top, each spanning multiple columns. Data is in paired columns, with the first column being the statistic and the second column being its standard error. The first row is a title, which we don’t need, and the 4th row is also not needed. We’ll first tidy-fy this dataset, and then we’ll clean it up a bit. Let’s first think about the structure we want to get to for tidy-fication. The actual data lies in the statistics and the standard errors, and each of the column groupings represents different variables, so they should be in columns. You can try to load this data using import, but you’ll find it’s a big mess. There are two powerful packages (by the same group of developers), tidyxl and unpivotr, that are fantastic tools for “fixing” Excel files for analysis. Let’s start with tidyxl. library(tidyxl) ## Warning: package &#39;tidyxl&#39; was built under R version 3.5.2 dataset1 &lt;- xlsx_cells(&#39;data/attendance.xlsx&#39;) dataset1 ## # A tibble: 1,173 x 21 ## sheet address row col is_blank data_type error logical numeric ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;lgl&gt; &lt;chr&gt; &lt;chr&gt; &lt;lgl&gt; &lt;dbl&gt; ## 1 Tabl… A1 1 1 FALSE character &lt;NA&gt; NA NA ## 2 Tabl… B1 1 2 TRUE blank &lt;NA&gt; NA NA ## 3 Tabl… C1 1 3 TRUE blank &lt;NA&gt; NA NA ## 4 Tabl… D1 1 4 TRUE blank &lt;NA&gt; NA NA ## 5 Tabl… E1 1 5 TRUE blank &lt;NA&gt; NA NA ## 6 Tabl… F1 1 6 TRUE blank &lt;NA&gt; NA NA ## 7 Tabl… G1 1 7 TRUE blank &lt;NA&gt; NA NA ## 8 Tabl… H1 1 8 TRUE blank &lt;NA&gt; NA NA ## 9 Tabl… I1 1 9 TRUE blank &lt;NA&gt; NA NA ## 10 Tabl… J1 1 10 TRUE blank &lt;NA&gt; NA NA ## # … with 1,163 more rows, and 12 more variables: date &lt;dttm&gt;, ## # character &lt;chr&gt;, character_formatted &lt;list&gt;, formula &lt;chr&gt;, ## # is_array &lt;lgl&gt;, formula_ref &lt;chr&gt;, formula_group &lt;int&gt;, comment &lt;chr&gt;, ## # height &lt;dbl&gt;, width &lt;dbl&gt;, style_format &lt;chr&gt;, local_format_id &lt;int&gt; Notice that this pulls in a lot of meta-data in a tidy form, including information about cell formatting. This will be really useful in many situations. First, lets get rid of the rows we don’t need. dataset1 &lt;- dataset1 %&gt;% filter(row != 1, row != 4, row &lt; 65) Now we could manipulate this dataset using tidyverse tools, but unpivotr is much mor poweful. First, we are going to pull off the two headers. unpivotr does this using the function behead (suggestive?), with the first argument being the direction (‘N’, “S”, ‘E’,‘W’,etc) of the table that the header is present. We will also consider the first column, consisting of state names, as a header on the left. library(unpivotr) ## Warning: package &#39;unpivotr&#39; was built under R version 3.5.2 dataset1 %&gt;% behead(&#39;N&#39;, tophead) %&gt;% behead(&#39;N&#39;, head2) %&gt;% behead(&#39;W&#39;, State) %&gt;% select(row, col, data_type, numeric, tophead, head2, State) ## # A tibble: 960 x 7 ## row col data_type numeric tophead head2 State ## &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 5 2 numeric 9.31e+1 Total elementary, se… ADA as p… &quot; Unit… ## 2 5 3 numeric 2.19e-1 &lt;NA&gt; &lt;NA&gt; &quot; Unit… ## 3 5 4 numeric 6.64e+0 &lt;NA&gt; Average … &quot; Unit… ## 4 5 5 numeric 1.76e-2 &lt;NA&gt; &lt;NA&gt; &quot; Unit… ## 5 5 6 numeric 1.80e+2 &lt;NA&gt; Average … &quot; Unit… ## 6 5 7 numeric 1.43e-1 &lt;NA&gt; &lt;NA&gt; &quot; Unit… ## 7 5 8 numeric 1.19e+3 &lt;NA&gt; Average … &quot; Unit… ## 8 5 9 numeric 3.09e+0 &lt;NA&gt; &lt;NA&gt; &quot; Unit… ## 9 5 10 numeric 9.40e+1 Elementary schools ADA as p… &quot; Unit… ## 10 5 11 numeric 2.69e-1 &lt;NA&gt; &lt;NA&gt; &quot; Unit… ## # … with 950 more rows We need to separate the statistics and the standard errors from consecutive columns, and also make them headers. dataset1 %&gt;% behead(&#39;N&#39;, tophead) %&gt;% behead(&#39;N&#39;, head2) %&gt;% behead(&#39;W&#39;, State) %&gt;% select(row, col, data_type, numeric, tophead, head2, State) %&gt;% mutate(header = ifelse(col %% 2 == 0, &#39;stats&#39;,&#39;se&#39;)) ## # A tibble: 960 x 8 ## row col data_type numeric tophead head2 State header ## &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 5 2 numeric 9.31e+1 Total elementar… ADA as … &quot; Uni… stats ## 2 5 3 numeric 2.19e-1 &lt;NA&gt; &lt;NA&gt; &quot; Uni… se ## 3 5 4 numeric 6.64e+0 &lt;NA&gt; Average… &quot; Uni… stats ## 4 5 5 numeric 1.76e-2 &lt;NA&gt; &lt;NA&gt; &quot; Uni… se ## 5 5 6 numeric 1.80e+2 &lt;NA&gt; Average… &quot; Uni… stats ## 6 5 7 numeric 1.43e-1 &lt;NA&gt; &lt;NA&gt; &quot; Uni… se ## 7 5 8 numeric 1.19e+3 &lt;NA&gt; Average… &quot; Uni… stats ## 8 5 9 numeric 3.09e+0 &lt;NA&gt; &lt;NA&gt; &quot; Uni… se ## 9 5 10 numeric 9.40e+1 Elementary scho… ADA as … &quot; Uni… stats ## 10 5 11 numeric 2.69e-1 &lt;NA&gt; &lt;NA&gt; &quot; Uni… se ## # … with 950 more rows The %% operator computes the remainder if the left side is divided by the right side. So the criterion is asking which columns are even. The ifelse statement says, if the criterion is met, write “stats”, otherwise write “se”. This new variable is assigned to the dataset with the variable name “header”. Notice that we have actually tidy-fied this dataset, but there’s missing data here, since the column headers span several rows visually but are only credited to the first column it covers. So we need to fill in the entries for the remaining rows with the corresponding entry from the earliest column. There is a function fill in tidyr that does this general trick, using a method called last value carried forward. dataset1 %&gt;% behead(&#39;N&#39;, tophead) %&gt;% behead(&#39;N&#39;, head2) %&gt;% behead(&#39;W&#39;, State) %&gt;% select(row, col, data_type, numeric, tophead, head2, State) %&gt;% fill(tophead) %&gt;% fill(head2) ## # A tibble: 960 x 7 ## row col data_type numeric tophead head2 State ## &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 5 2 numeric 9.31e+1 Total elementary, se… ADA as p… &quot; Unit… ## 2 5 3 numeric 2.19e-1 Total elementary, se… ADA as p… &quot; Unit… ## 3 5 4 numeric 6.64e+0 Total elementary, se… Average … &quot; Unit… ## 4 5 5 numeric 1.76e-2 Total elementary, se… Average … &quot; Unit… ## 5 5 6 numeric 1.80e+2 Total elementary, se… Average … &quot; Unit… ## 6 5 7 numeric 1.43e-1 Total elementary, se… Average … &quot; Unit… ## 7 5 8 numeric 1.19e+3 Total elementary, se… Average … &quot; Unit… ## 8 5 9 numeric 3.09e+0 Total elementary, se… Average … &quot; Unit… ## 9 5 10 numeric 9.40e+1 Elementary schools ADA as p… &quot; Unit… ## 10 5 11 numeric 2.69e-1 Elementary schools ADA as p… &quot; Unit… ## # … with 950 more rows To make this really tidy, we need to make two columns titled stats and se from this. We’ve seen this using spread, but there is a slightly more robust method from unpivotr called spatter which is meant for this unique structure. tidy_dataset &lt;- dataset1 %&gt;% behead(&#39;N&#39;, tophead) %&gt;% behead(&#39;N&#39;, head2) %&gt;% behead(&#39;W&#39;, State) %&gt;% select(row, col, data_type, numeric, tophead, head2, State) %&gt;% mutate(header = ifelse(col %% 2 == 0, &#39;stats&#39;,&#39;se&#39;)) %&gt;% fill(tophead) %&gt;% fill(head2) %&gt;% select(row, numeric, tophead, head2, State, header) %&gt;% spatter(header, numeric) %&gt;% select(-row) tidy_dataset ## # A tibble: 480 x 5 ## tophead head2 State se stats ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Elementary schools ADA as percen… &quot; United … 0.269 9.40e1 ## 2 Elementary schools Average hours… &quot; United … 0.0160 6.66e0 ## 3 Secondary schools ADA as percen… &quot; United … 0.432 9.11e1 ## 4 Secondary schools Average hours… &quot; United … 0.0403 6.59e0 ## 5 Total elementary, secondary, … ADA as percen… &quot; United … 0.219 9.31e1 ## 6 Total elementary, secondary, … Average days … &quot; United … 0.143 1.80e2 ## 7 Total elementary, secondary, … Average hours… &quot; United … 0.0176 6.64e0 ## 8 Total elementary, secondary, … Average hours… &quot; United … 3.09 1.19e3 ## 9 Elementary schools ADA as percen… Alabama ...… 1.84 9.38e1 ## 10 Elementary schools Average hours… Alabama ...… 0.0759 7.04e0 ## # … with 470 more rows We have to clean the State variable. We’ll use the methods in the stringr package, which is already loaded with the tidyverse. tidy_dataset &lt;- tidy_dataset %&gt;% mutate(State = str_remove(State, &#39;\\\\.+&#39;)) %&gt;% mutate(State = str_trim(State)) The first verb removes all the . in the variable, using something called a regular expression. This particular expression means that we want to look for sequences of dots, and remove them. The \\\\ before the . tells R that we really mean ., since the . has a different meaning in regular expressions. The second verb trims away blank spaces before and after each entry. We’ll hold on to this dataset for the visualization section. Just to be safe, let’s save it. saveRDS(tidy_dataset, file = &#39;data/attendance.rds&#39;) This saves the data in an R-specific format that will allow us to load it quickly. The RDS format is an open standard and so it can be called from other programs if the appropriate programs are written. Dealing with visual formating (colors) The dataset we’ll use for this has identifiable information, so I will not expose it publicly. It is available in your files as data/classlist.xlsx. Since we’re interested in background and font colors here, which are informative, we also need to load the format information into R. library(tidyxl) library(unpivotr) dataset2 &lt;- xlsx_cells(&#39;data/classlist.xlsx&#39;) formats &lt;- xlsx_formats(&#39;data/classlist.xlsx&#39;) format_id &lt;- dataset2$local_format_id dataset2$font_color &lt;- formats$local$font$color$rgb[format_id] dataset2$bg_color &lt;- formats$local$fill$patternFill$fgColor$rgb[format_id] unique(dataset2$font_color) ## [1] &quot;FF000000&quot; &quot;FF0563C1&quot; &quot;FFFF0000&quot; unique(dataset2$bg_color) ## [1] &quot;FFFFC000&quot; NA &quot;FFE7E6E6&quot; So we can filter rows based on these two colors if we want. To tidy-fy this dataset, we realize that there are really two interweaved datasets. The odd rows are one dataset and the even rows are another dataset. dat1 &lt;- dataset2 %&gt;% filter( row %% 2 == 1) %&gt;% # odd rows behead(&#39;N&#39;, header) %&gt;% mutate(row = (row+1)/2) # make the row numbers sequential dat2 &lt;- dataset2 %&gt;% filter(row %% 2 == 0) %&gt;% # even rows behead(&#39;N&#39;, header) %&gt;% mutate(row = row/2) %&gt;% # make row numbers sequential mutate(col = col+4) # These will be the last 4 cols of new data tidy_dataset2 &lt;- rbind(dat1, dat2) %&gt;% # Put datsets on top of each other select(row, data_type, numeric, character, header) %&gt;% spatter(header) %&gt;% select(-row, -numeric) We’ll do a couple of finesse things to finish. First, we’ll make the names with no spaces (they’re a pain to write otherwise) and put the student name on the first column. tidy_dataset2 &lt;- tidy_dataset2 %&gt;% set_names(make.names(names(.))) %&gt;% select(Student.Name, everything()) make.names changes a vector of names into “approved” space-free format, replacing the space with .. One shortcut I’ve used is using . as an argument to names, which means that the . is replaced by the “noun” that is being acted on by the “verbs”. You will notice that I can also do multiple verbs together to work sequentially. "],
["sec-description.html", "Chapter 5 Describing data", " Chapter 5 Describing data Data cleaning and munging is important, yet tedious work. Now that we’re done with that, we can get to the fun part of exploring the data. Our workhorse for this will be the dplyr package, part of the tidyverse. This package provides 5 basic verbs: filter: filter a dataset by rows select: select columns of a dataset arrange: arrange rows of a dataset by values of some variables group_by: split a dataset by values of some variables, so that we can apply verbs to each split summarize: compute various summaries from the data dplyr also has verbs to let stitch datasets together, which are left_join, right_join, inner_join, outer_join, semi_join, anti_join, bind_rows and bind_cols. I’ll be using the latest dplyr, version 0.8.0.9009. If you have an older version, most but not all things will work. We’ll start with the in-build mtcars dataset. library(tidyverse) mtcars1 &lt;- mtcars %&gt;% rownames_to_column(&#39;cars&#39;) %&gt;% as_tibble() mtcars1 ## # A tibble: 32 x 12 ## cars mpg cyl disp hp drat wt qsec vs am gear carb ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Mazda… 21 6 160 110 3.9 2.62 16.5 0 1 4 4 ## 2 Mazda… 21 6 160 110 3.9 2.88 17.0 0 1 4 4 ## 3 Datsu… 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 ## 4 Horne… 21.4 6 258 110 3.08 3.22 19.4 1 0 3 1 ## 5 Horne… 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 ## 6 Valia… 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 ## 7 Duste… 14.3 8 360 245 3.21 3.57 15.8 0 0 3 4 ## 8 Merc … 24.4 4 147. 62 3.69 3.19 20 1 0 4 2 ## 9 Merc … 22.8 4 141. 95 3.92 3.15 22.9 1 0 4 2 ## 10 Merc … 19.2 6 168. 123 3.92 3.44 18.3 1 0 4 4 ## # … with 22 more rows Let’s get some summary statistics from this dataset. First, let’s compute the average mpg, displacement, and horsepower of these cars. mtcars1 %&gt;% summarize(mpg = mean(mpg, na.rm=T), disp = mean(disp, na.rm=T), hp = mean(hp, na.rm=T)) ## # A tibble: 1 x 3 ## mpg disp hp ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 20.1 231. 147. I’m adding the option na.rm=T to remove any missing values; if there is even a single missing value, the mean will be computed as NA Most dplyr verbs also have scoped versions *_all, *_at, *_if, which can be useful. The *_any versions act upon all the columns, the *_at versions on specified columns (same way columns are specified in select) and the *_if versions on columns with particular properties. So the above code could be written as mtcars1 %&gt;% summarize_at(vars(mpg, disp, hp), mean, na.rm = T) ## # A tibble: 1 x 3 ## mpg disp hp ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 20.1 231. 147. Factors or categorical variables R has a data type called a factor, which is meant for categorical or discrete variables; things like sex, race, and, in this data, cyl. We need to transform the column to this data type first. mtcars1 &lt;- mtcars1 %&gt;% mutate(cyl = as.factor(cyl)) There are a few others that might need this treatment. mtcars1 &lt;- mtcars1 %&gt;% mutate_at(vars(cyl, vs, am, gear, carb), as.factor) Let’s see what we’ve done. str(mtcars1) ## Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 32 obs. of 12 variables: ## $ cars: chr &quot;Mazda RX4&quot; &quot;Mazda RX4 Wag&quot; &quot;Datsun 710&quot; &quot;Hornet 4 Drive&quot; ... ## $ mpg : num 21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ... ## $ cyl : Factor w/ 3 levels &quot;4&quot;,&quot;6&quot;,&quot;8&quot;: 2 2 1 2 3 2 3 1 1 2 ... ## $ disp: num 160 160 108 258 360 ... ## $ hp : num 110 110 93 110 175 105 245 62 95 123 ... ## $ drat: num 3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ... ## $ wt : num 2.62 2.88 2.32 3.21 3.44 ... ## $ qsec: num 16.5 17 18.6 19.4 17 ... ## $ vs : Factor w/ 2 levels &quot;0&quot;,&quot;1&quot;: 1 1 2 2 1 2 1 2 2 2 ... ## $ am : Factor w/ 2 levels &quot;0&quot;,&quot;1&quot;: 2 2 2 1 1 1 1 1 1 1 ... ## $ gear: Factor w/ 3 levels &quot;3&quot;,&quot;4&quot;,&quot;5&quot;: 2 2 2 1 1 1 1 2 2 2 ... ## $ carb: Factor w/ 6 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,..: 4 4 1 1 2 1 4 2 2 4 ... Now, let’s compute averages of all the non-factor, or numeric, variables. mtcars1 %&gt;% summarize_if(is.numeric, mean) ## # A tibble: 1 x 6 ## mpg disp hp drat wt qsec ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 20.1 231. 147. 3.60 3.22 17.8 We can get a summary of all the variables using the function summary. summary(mtcars1) ## cars mpg cyl disp hp ## Length:32 Min. :10.40 4:11 Min. : 71.1 Min. : 52.0 ## Class :character 1st Qu.:15.43 6: 7 1st Qu.:120.8 1st Qu.: 96.5 ## Mode :character Median :19.20 8:14 Median :196.3 Median :123.0 ## Mean :20.09 Mean :230.7 Mean :146.7 ## 3rd Qu.:22.80 3rd Qu.:326.0 3rd Qu.:180.0 ## Max. :33.90 Max. :472.0 Max. :335.0 ## drat wt qsec vs am gear ## Min. :2.760 Min. :1.513 Min. :14.50 0:18 0:19 3:15 ## 1st Qu.:3.080 1st Qu.:2.581 1st Qu.:16.89 1:14 1:13 4:12 ## Median :3.695 Median :3.325 Median :17.71 5: 5 ## Mean :3.597 Mean :3.217 Mean :17.85 ## 3rd Qu.:3.920 3rd Qu.:3.610 3rd Qu.:18.90 ## Max. :4.930 Max. :5.424 Max. :22.90 ## carb ## 1: 7 ## 2:10 ## 3: 3 ## 4:10 ## 6: 1 ## 8: 1 However, this does not give us a tidy dataset. Some alternatives are the skimr package and the ezsummary package. # install.packages(&#39;skimr&#39;) library(skimr) ## Warning: package &#39;skimr&#39; was built under R version 3.5.2 ## ## Attaching package: &#39;skimr&#39; ## The following object is masked from &#39;package:stats&#39;: ## ## filter skim(mtcars1) ## Skim summary statistics ## n obs: 32 ## n variables: 12 ## ## ── Variable type:character ─────────────────────────────────────────── ## variable missing complete n min max empty n_unique ## cars 0 32 32 7 19 0 32 ## ## ── Variable type:factor ────────────────────────────────────────────── ## variable missing complete n n_unique top_counts ordered ## am 0 32 32 2 0: 19, 1: 13, NA: 0 FALSE ## carb 0 32 32 6 2: 10, 4: 10, 1: 7, 3: 3 FALSE ## cyl 0 32 32 3 8: 14, 4: 11, 6: 7, NA: 0 FALSE ## gear 0 32 32 3 3: 15, 4: 12, 5: 5, NA: 0 FALSE ## vs 0 32 32 2 0: 18, 1: 14, NA: 0 FALSE ## ## ── Variable type:numeric ───────────────────────────────────────────── ## variable missing complete n mean sd p0 p25 p50 p75 ## disp 0 32 32 230.72 123.94 71.1 120.83 196.3 326 ## drat 0 32 32 3.6 0.53 2.76 3.08 3.7 3.92 ## hp 0 32 32 146.69 68.56 52 96.5 123 180 ## mpg 0 32 32 20.09 6.03 10.4 15.43 19.2 22.8 ## qsec 0 32 32 17.85 1.79 14.5 16.89 17.71 18.9 ## wt 0 32 32 3.22 0.98 1.51 2.58 3.33 3.61 ## p100 hist ## 472 ▇▆▁▂▅▃▁▂ ## 4.93 ▃▇▁▅▇▂▁▁ ## 335 ▃▇▃▅▂▃▁▁ ## 33.9 ▃▇▇▇▃▂▂▂ ## 22.9 ▃▂▇▆▃▃▁▁ ## 5.42 ▃▃▃▇▆▁▁▂ "],
["split-apply-combine-a-k-a-mapreduce.html", "5.1 Split-apply-combine, a.k.a. MapReduce", " 5.1 Split-apply-combine, a.k.a. MapReduce The split-apply-combine is a powerful paradigm for understanding subgroups within a dataset. The basic idea is that you split the data into pieces based on values of some variables, do something (the same thing) to each piece, and then stitch the results back together. For example, in the mtcars data, we might want to know what the average mpg is by the number of cylinders. The way to do this is: mtcars1 %&gt;% group_by(cyl) %&gt;% summarize(mpg_mean = mean(mpg)) ## # A tibble: 3 x 2 ## cyl mpg_mean ## &lt;fct&gt; &lt;dbl&gt; ## 1 4 26.7 ## 2 6 19.7 ## 3 8 15.1 Once again, the scoped versions of summarize will also work in this pipe mtcars1 %&gt;% group_by(cyl) %&gt;% summarize_if(is.numeric, mean) ## # A tibble: 3 x 7 ## cyl mpg disp hp drat wt qsec ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 4 26.7 105. 82.6 4.07 2.29 19.1 ## 2 6 19.7 183. 122. 3.59 3.12 18.0 ## 3 8 15.1 353. 209. 3.23 4.00 16.8 Let’s go a bit further and compute the medians as well. mtcars1 %&gt;% group_by(cyl) %&gt;% summarize_if(is.numeric, list(&#39;mean&#39;= mean, &#39;median&#39; = median)) ## # A tibble: 3 x 13 ## cyl mpg_mean disp_mean hp_mean drat_mean wt_mean qsec_mean mpg_median ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 4 26.7 105. 82.6 4.07 2.29 19.1 26 ## 2 6 19.7 183. 122. 3.59 3.12 18.0 19.7 ## 3 8 15.1 353. 209. 3.23 4.00 16.8 15.2 ## # … with 5 more variables: disp_median &lt;dbl&gt;, hp_median &lt;dbl&gt;, ## # drat_median &lt;dbl&gt;, wt_median &lt;dbl&gt;, qsec_median &lt;dbl&gt; We can look at a second dataset showing individual violent incidents in Western Afrika between 2000 and 2017. We can get the number of incidents per country and year very easily using this paradigm. west_africa &lt;- import(&#39;data/2000-01-01-2019-01-01-Western_Africa.csv&#39;) west_africa %&gt;% group_by(country, year) %&gt;% tally() ## # A tibble: 290 x 3 ## # Groups: country [15] ## country year n ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 Benin 2000 1 ## 2 Benin 2001 3 ## 3 Benin 2002 1 ## 4 Benin 2003 2 ## 5 Benin 2004 2 ## 6 Benin 2005 2 ## 7 Benin 2006 1 ## 8 Benin 2007 3 ## 9 Benin 2008 1 ## 10 Benin 2009 2 ## # … with 280 more rows For display, we can make this a wide dataset west_africa %&gt;% group_by(country, year) %&gt;% tally() %&gt;% spread(year, n) ## # A tibble: 15 x 21 ## # Groups: country [15] ## country `2000` `2001` `2002` `2003` `2004` `2005` `2006` `2007` `2008` ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 Benin 1 3 1 2 2 2 1 3 1 ## 2 Burkin… 22 6 6 1 4 6 8 1 12 ## 3 Gambia 8 14 13 11 5 4 6 2 4 ## 4 Ghana 10 8 7 17 7 3 3 5 11 ## 5 Guinea 180 70 14 10 11 15 7 46 15 ## 6 Guinea… 9 2 3 5 4 13 21 2 2 ## 7 Ivory … 133 34 135 177 101 45 30 6 24 ## 8 Liberia 87 171 148 242 22 26 22 9 17 ## 9 Mali 4 5 2 3 3 2 10 11 21 ## 10 Maurit… 4 1 3 13 2 9 3 5 16 ## 11 Niger 11 9 42 6 17 9 8 31 28 ## 12 Nigeria 168 118 160 207 277 198 120 200 208 ## 13 Senegal 86 61 40 18 11 11 29 24 20 ## 14 Sierra… 495 224 5 18 14 5 1 6 15 ## 15 Togo 4 4 3 4 3 25 1 1 1 ## # … with 11 more variables: `2009` &lt;int&gt;, `2010` &lt;int&gt;, `2011` &lt;int&gt;, ## # `2012` &lt;int&gt;, `2013` &lt;int&gt;, `2014` &lt;int&gt;, `2015` &lt;int&gt;, `2016` &lt;int&gt;, ## # `2017` &lt;int&gt;, `2018` &lt;int&gt;, `2019` &lt;int&gt; We’ll save this dataset for visualization later. west_africa %&gt;% group_by(country, year) %&gt;% tally() %&gt;% spread(year, n) %&gt;% saveRDS(&#39;data/west_africa.rds&#39;) "],
["joins.html", "5.2 Joins", " 5.2 Joins We mentioned earlier that there are several kinds of ways we can join data. The different kinds of joins are described below. Let’s look at these joins with an example. We have two simulated datasets looking at DOS real estate allocation and staffing. We will look at how much area on average each bureau has given the number of employees staffing_data &lt;- import(&#39;data/Staffing_by_Bureau.csv&#39;) %&gt;% as_tibble() real_estate &lt;- import(&#39;data/DoS_Real_Estate_Allocation.csv&#39;) %&gt;% as_tibble() real_estate ## # A tibble: 666 x 4 ## Building Bureau Location Size ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 HST Administration (A) 4779 640 ## 2 SA2 Administration (A) 4801 1090 ## 3 HST Administration (A) 5109 1040 ## 4 HST Administration (A) 3717 1620 ## 5 SA4 Administration (A) 3940 1390 ## 6 HST Administration (A) 3661 1480 ## 7 HST Administration (A) 3374 1770 ## 8 HST Administration (A) 3387 1940 ## 9 SA10 African Affairs (AF) 2605 640 ## 10 HST African Affairs (AF) 3573 720 ## # … with 656 more rows staffing_data ## # A tibble: 10,000 x 6 ## Bureau Gender Grade Title Name YearsService ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 Protocol (S/CPR) female FS1 Manager Cathy Ca… 13 ## 2 Administration (A) male GS-9 Team Me… Jeffery … 13 ## 3 Intelligence and Research … male FS-6 Analyst Max Green 11 ## 4 Mission to the United Nati… male FS-3 Manager Donald A… 7 ## 5 Foreign Missions (OFM) male FS-6 Team Me… Thomas L… 22 ## 6 International Narcotics an… male GS-8 Team Me… Joseph A… 12 ## 7 Administration (A) male GS-12 Analyst Michael … 6 ## 8 Intelligence and Research … male FS-5 Team Me… Jesus Sh… 2 ## 9 Science &amp; Technology Advis… male N/A Manager Lawrence… 19 ## 10 Administration (A) female FS-8 Team Me… Jennie C… 17 ## # … with 9,990 more rows The strategy is going to be to do a grouped summary of the staffing data to see how many people are in each Bureau, and then join that with the real estate data to compute the average area per employee by Bureau. staff_summary &lt;- staffing_data %&gt;% group_by(Bureau) %&gt;% tally(name = &#39;Pop&#39;) realestate_summary &lt;- real_estate %&gt;% group_by(Bureau) %&gt;% summarize(Size = sum(Size)) realestate_summary %&gt;% left_join(staff_summary) %&gt;% mutate(unit_area = Size/Pop) %&gt;% arrange(unit_area) ## Joining, by = &quot;Bureau&quot; ## # A tibble: 54 x 4 ## Bureau Size Pop unit_area ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Global Youth Issues (GYI) 2090 345 6.06 ## 2 Policy Planning Staff (S/P) 2420 240 10.1 ## 3 Science &amp; Technology Adviser (STAS) 4240 305 13.9 ## 4 Foreign Missions (OFM) 4420 311 14.2 ## 5 Trafficking in Persons (TIP) 5150 247 20.9 ## 6 Medical Services (MED) 6760 308 21.9 ## 7 Protocol (S/CPR) 7730 327 23.6 ## 8 Administration (A) 10970 454 24.2 ## 9 Oceans and International Environmental and Scient… 8420 330 25.5 ## 10 Energy Resources (ENR) 10890 369 29.5 ## # … with 44 more rows "],
["the-select-function.html", "5.3 The select function", " 5.3 The select function The select function selects variables (columns) from your dataset. We will look at some nice selection methods using a dataset of all foreign aid disbursements from Department of State between 2004 and 2017. library(rio) dos &lt;- import(&#39;data/Department of State.csv&#39;) %&gt;% as_tibble() names(dos) [1] &quot;Award_Identifier&quot; [2] &quot;Extending_Organization&quot; [3] &quot;Extending_Organization_Office&quot; [4] &quot;Accountable_Organization&quot; [5] &quot;Accountable_Organization_Office&quot; [6] &quot;Implementing_Organization&quot; [7] &quot;Implementing_Organization_Type&quot; [8] &quot;Implementing_Organization_Country&quot; [9] &quot;Implementing_Organization_DUNS_Number&quot; [10] &quot;Award_Title&quot; [11] &quot;Award_Description&quot; [12] &quot;Award_Status&quot; [13] &quot;Award_Collaboration_Type&quot; [14] &quot;Award_Total_Estimated_Value&quot; [15] &quot;Award_Interagency_Transfer_Status&quot; [16] &quot;Award_Start_Date&quot; [17] &quot;Award_End_Date&quot; [18] &quot;Recipient_Location&quot; [19] &quot;Award_Transaction_Description&quot; [20] &quot;Award_Transaction_Value&quot; [21] &quot;Award_Transaction_Type&quot; [22] &quot;Award_Transaction_Date&quot; [23] &quot;Award_Transaction_Fiscal_Year&quot; [24] &quot;Award_Transaction_Fiscal_Quarter&quot; [25] &quot;Award_Transaction_Aid_Type&quot; [26] &quot;Award_Transaction_Tied_Status&quot; [27] &quot;Award_Transaction_Flow_Type&quot; [28] &quot;Award_Transaction_Finance_Type&quot; [29] &quot;Award_Transaction_DAC_Purpose_Code&quot; [30] &quot;Award_Transaction_DAC_Purpose_Code_Name&quot; [31] &quot;Award_Transaction_US_Foreign_Assistance_Code&quot; [32] &quot;Award_Transaction_US_Foreign_Assistance_Category&quot; [33] &quot;Award_Transaction_US_Foreign_Assistance_Sector&quot; [34] &quot;Treasury_Account_Codes&quot; [35] &quot;Treasury_Account_Title&quot; [36] &quot;Treasury_Account_Start_Fiscal_Year&quot; [37] &quot;Treasury_Account_End_Fiscal_Year&quot; [38] &quot;Data_Submission_Date&quot; There are several groups of variables by name, and dplyr provides nice functions to extract them. # A tibble: 558,878 x 24 Award_Identifier Award_Title Award_Descripti… Award_Status &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; 1 1040240201 &quot;&quot; Ambassadors-At-… Implementat… 2 1040240201 &quot;&quot; Ambassadors-At-… Implementat… 3 1040240201 &quot;&quot; Ambassadors-At-… Implementat… 4 1040240220 &quot;&quot; Ambassadors-At-… Implementat… 5 1040240202 &quot;&quot; Ambassadors-At-… Implementat… 6 1040240202 &quot;&quot; Ambassadors-At-… Implementat… 7 1040240204 &quot;&quot; Ambassadors-At-… Implementat… 8 1040240204 &quot;&quot; Ambassadors-At-… Implementat… 9 1040240225 &quot;&quot; Ambassadors-At-… Implementat… 10 1040240225 &quot;&quot; Ambassadors-At-… Implementat… # … with 558,868 more rows, and 20 more variables: # Award_Collaboration_Type &lt;chr&gt;, Award_Total_Estimated_Value &lt;dbl&gt;, # Award_Interagency_Transfer_Status &lt;chr&gt;, Award_Start_Date &lt;chr&gt;, # Award_End_Date &lt;chr&gt;, Award_Transaction_Description &lt;chr&gt;, # Award_Transaction_Value &lt;dbl&gt;, Award_Transaction_Type &lt;chr&gt;, # Award_Transaction_Date &lt;chr&gt;, Award_Transaction_Fiscal_Year &lt;int&gt;, # Award_Transaction_Fiscal_Quarter &lt;int&gt;, # Award_Transaction_Aid_Type &lt;chr&gt;, Award_Transaction_Tied_Status &lt;chr&gt;, # Award_Transaction_Flow_Type &lt;chr&gt;, # Award_Transaction_Finance_Type &lt;chr&gt;, # Award_Transaction_DAC_Purpose_Code &lt;int&gt;, # Award_Transaction_DAC_Purpose_Code_Name &lt;chr&gt;, # Award_Transaction_US_Foreign_Assistance_Code &lt;int&gt;, # Award_Transaction_US_Foreign_Assistance_Category &lt;chr&gt;, # Award_Transaction_US_Foreign_Assistance_Sector &lt;chr&gt; dos %&gt;% select(ends_with(&quot;Value&quot;)) # A tibble: 558,878 x 2 Award_Total_Estimated_Value Award_Transaction_Value &lt;dbl&gt; &lt;dbl&gt; 1 0 194. 2 0 301. 3 0 287. 4 0 2470. 5 0 1031. 6 0 2853. 7 0 3431. 8 0 912. 9 0 525. 10 0 1436. # … with 558,868 more rows dos %&gt;% select(contains(&quot;Transaction&quot;)) # A tibble: 558,878 x 15 Award_Transacti… Award_Transacti… Award_Transacti… Award_Transacti… &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; 1 &quot;&quot; 194. Disbursement 2011-11-30 00:0… 2 &quot;&quot; 301. Commitment 2011-10-31 00:0… 3 &quot;&quot; 287. Disbursement 2011-10-31 00:0… 4 &quot;&quot; 2470. Commitment 2011-10-31 00:0… 5 &quot;&quot; 1031. Commitment 2011-11-30 00:0… 6 &quot;&quot; 2853. Disbursement 2011-11-30 00:0… 7 &quot;&quot; 3431. Disbursement 2011-12-31 00:0… 8 &quot;&quot; 912. Disbursement 2011-11-30 00:0… 9 &quot;&quot; 525. Commitment 2011-12-31 00:0… 10 &quot;&quot; 1436. Disbursement 2011-12-31 00:0… # … with 558,868 more rows, and 11 more variables: # Award_Transaction_Fiscal_Year &lt;int&gt;, # Award_Transaction_Fiscal_Quarter &lt;int&gt;, # Award_Transaction_Aid_Type &lt;chr&gt;, Award_Transaction_Tied_Status &lt;chr&gt;, # Award_Transaction_Flow_Type &lt;chr&gt;, # Award_Transaction_Finance_Type &lt;chr&gt;, # Award_Transaction_DAC_Purpose_Code &lt;int&gt;, # Award_Transaction_DAC_Purpose_Code_Name &lt;chr&gt;, # Award_Transaction_US_Foreign_Assistance_Code &lt;int&gt;, # Award_Transaction_US_Foreign_Assistance_Category &lt;chr&gt;, # Award_Transaction_US_Foreign_Assistance_Sector &lt;chr&gt; There are several other helper functions that can grab variables based on properities of their names. starts_with(): Starts with a prefix. ends_with(): Ends with a suffix. contains(): Contains a literal string. matches(): Matches a regular expression. num_range(): Matches a numerical range like x01, x02, x03. one_of(): Matches variable names in a character vector. everything(): Matches all variables. last_col(): Select last variable, possibly with an offset. We can pipe these too. In the next bit, we are trying to get the variables that representing start dates. We are using the pull function to grab the data out of the dataset in the form of an array, just so it’s easier to manipulate. start_dates &lt;- dos %&gt;% select(ends_with(&quot;Date&quot;)) %&gt;% select(contains(&quot;Start&quot;)) %&gt;% pull(1) head(start_dates) [1] &quot;2011-10-05 00:00:00&quot; &quot;2011-10-05 00:00:00&quot; &quot;2011-10-05 00:00:00&quot; [4] &quot;2011-10-21 00:00:00&quot; &quot;2011-10-03 00:00:00&quot; &quot;2011-10-03 00:00:00&quot; "],
["dates.html", "5.4 Dates", " 5.4 Dates Resource: RStudio cheatsheet Dates are a first-class data type in R, though they are natively somewhat difficult to manage. The package lubridate added several convenience functions to make this work much easier. library(lubridate) Attaching package: &#39;lubridate&#39; The following object is masked from &#39;package:base&#39;: date start_dates &lt;- as_date(start_dates) %&gt;% head() start_dates [1] &quot;2011-10-05&quot; &quot;2011-10-05&quot; &quot;2011-10-05&quot; &quot;2011-10-21&quot; &quot;2011-10-03&quot; [6] &quot;2011-10-03&quot; year(start_dates) [1] 2011 2011 2011 2011 2011 2011 month(start_dates) [1] 10 10 10 10 10 10 day(start_dates) [1] 5 5 5 21 3 3 sort(start_dates) [1] &quot;2011-10-03&quot; &quot;2011-10-03&quot; &quot;2011-10-05&quot; &quot;2011-10-05&quot; &quot;2011-10-05&quot; [6] &quot;2011-10-21&quot; quarter(start_dates) [1] 4 4 4 4 4 4 days(start_dates) - days(as_date(&#39;2011-10-01&#39;)) # Days from start of fiscal year [1] &quot;4d 0H 0M 0S&quot; &quot;4d 0H 0M 0S&quot; &quot;4d 0H 0M 0S&quot; &quot;20d 0H 0M 0S&quot; [5] &quot;2d 0H 0M 0S&quot; &quot;2d 0H 0M 0S&quot; So we see that we can do math with dates to identify intervals of time, in appropriate units. "],
["joins-1.html", "Chapter 6 Joins", " Chapter 6 Joins We are often in the situation that pieces of data are resident in different tables, and we need to put them together for analyses. Usually each table will have some type of identifier variable that identifies the unit with which each observation is associated. Joins use these identifiers to put datasets together while maintaining correspondence of the data with the actual units. There are 4 primary kinds of joins: Let’s summarize what can happen with joins: Type Rows Columns inner same or decrease increase left same as left dataset increase right same as right dataset increase full increase increase We’ll play with two simulated datasets looking at staffing and real estate allocation at DOS. The question we’re asking is, what is the area avaiable per capita in each Bureau. staffing_data &lt;- import(&#39;data/Staffing_by_Bureau.csv&#39;) real_estate &lt;- import(&#39;data/DoS_Real_Estate_Allocation.csv&#39;) staffing_data %&gt;% as_tibble() # A tibble: 10,000 x 6 Bureau Gender Grade Title Name YearsService &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; 1 Protocol (S/CPR) female FS1 Manager Cathy Ca… 13 2 Administration (A) male GS-9 Team Me… Jeffery … 13 3 Intelligence and Research … male FS-6 Analyst Max Green 11 4 Mission to the United Nati… male FS-3 Manager Donald A… 7 5 Foreign Missions (OFM) male FS-6 Team Me… Thomas L… 22 6 International Narcotics an… male GS-8 Team Me… Joseph A… 12 7 Administration (A) male GS-12 Analyst Michael … 6 8 Intelligence and Research … male FS-5 Team Me… Jesus Sh… 2 9 Science &amp; Technology Advis… male N/A Manager Lawrence… 19 10 Administration (A) female FS-8 Team Me… Jennie C… 17 # … with 9,990 more rows real_estate %&gt;% as_tibble() # A tibble: 666 x 4 Building Bureau Location Size &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; 1 HST Administration (A) 4779 640 2 SA2 Administration (A) 4801 1090 3 HST Administration (A) 5109 1040 4 HST Administration (A) 3717 1620 5 SA4 Administration (A) 3940 1390 6 HST Administration (A) 3661 1480 7 HST Administration (A) 3374 1770 8 HST Administration (A) 3387 1940 9 SA10 African Affairs (AF) 2605 640 10 HST African Affairs (AF) 3573 720 # … with 656 more rows First we summarize the data by Bureau staff_summary &lt;- staffing_data %&gt;% group_by(Bureau) %&gt;% tally(name = &#39;Pop&#39;) realestate_summary &lt;- real_estate %&gt;% group_by(Bureau) %&gt;% summarize(Size = sum(Size)) staff_summary %&gt;% head(4) # A tibble: 4 x 2 Bureau Pop &lt;chr&gt; &lt;int&gt; 1 Administration (A) 454 2 African Affairs (AF) 42 3 Allowances (A/OPR/ALS) 90 4 Arms Control, Verification and Compliance (AVC) 98 realestate_summary %&gt;% head(4) # A tibble: 4 x 2 Bureau Size &lt;chr&gt; &lt;int&gt; 1 Administration (A) 10970 2 African Affairs (AF) 26750 3 Allowances (A/OPR/ALS) 3010 4 Arms Control, Verification and Compliance (AVC) 8410 Then we join the two datasets together. They will join based on the Bureau variable, which is common to both datasets. staff_summary %&gt;% inner_join(realestate_summary, by = c(&quot;Bureau&quot; = &quot;Bureau&quot;)) # A tibble: 54 x 3 Bureau Pop Size &lt;chr&gt; &lt;int&gt; &lt;int&gt; 1 Administration (A) 454 10970 2 African Affairs (AF) 42 26750 3 Allowances (A/OPR/ALS) 90 3010 4 Arms Control, Verification and Compliance (AVC) 98 8410 5 Budget and Planning (BP) 168 7500 6 Chief Information Officer (CIO) 222 11390 7 Comptroller and Global Financial Services (CGFS) 169 15700 8 Conflict and Stabilization Operations (CSO) 392 14970 9 Consular Affairs (CA) 141 36610 10 Counterterrorism (CT) 324 9980 # … with 44 more rows Once we have joined the datasets, we can now create a variable that computes the area per capita, and then we sort the rows of the data in order of descending area per capita. staff_summary %&gt;% inner_join(realestate_summary, by = c(&quot;Bureau&quot; = &quot;Bureau&quot;)) %&gt;% mutate(unit_area = Size/Pop) %&gt;% arrange(unit_area) # A tibble: 54 x 4 Bureau Pop Size unit_area &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; 1 Global Youth Issues (GYI) 345 2090 6.06 2 Policy Planning Staff (S/P) 240 2420 10.1 3 Science &amp; Technology Adviser (STAS) 305 4240 13.9 4 Foreign Missions (OFM) 311 4420 14.2 5 Trafficking in Persons (TIP) 247 5150 20.9 6 Medical Services (MED) 308 6760 21.9 7 Protocol (S/CPR) 327 7730 23.6 8 Administration (A) 454 10970 24.2 9 Oceans and International Environmental and Scient… 330 8420 25.5 10 Energy Resources (ENR) 369 10890 29.5 # … with 44 more rows "],
["data-summaries.html", "Chapter 7 Data summaries", " Chapter 7 Data summaries The dplyr package gives us 5 verbs to operate on a single data frame: filter: filter a dataset by rows select: select columns of a dataset arrange: arrange rows of a dataset by values of some variables group_by: split a dataset by values of some variables, so that we can apply verbs to each split summarize: compute various summaries from the data It also gives us verbs for joining 2 data frames: left_join right_join inner_join outer_join semi_join : Keep rows of left dataset which correspond to rows in right dataset anti_join : Keep rows of left dataset which do not correspond to rows in right dataset bind_rows : Stack two datasets on top of each other, provided they have the same number of columns bind_cols : Put two datasets side by side, provided they have the same number or rows. ] library(tidyverse) mtcars1 &lt;- mtcars %&gt;% rownames_to_column(&#39;cars&#39;) %&gt;% as_tibble() mtcars1 # A tibble: 32 x 12 cars mpg cyl disp hp drat wt qsec vs am gear carb &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 Mazda… 21 6 160 110 3.9 2.62 16.5 0 1 4 4 2 Mazda… 21 6 160 110 3.9 2.88 17.0 0 1 4 4 3 Datsu… 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 4 Horne… 21.4 6 258 110 3.08 3.22 19.4 1 0 3 1 5 Horne… 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 6 Valia… 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 7 Duste… 14.3 8 360 245 3.21 3.57 15.8 0 0 3 4 8 Merc … 24.4 4 147. 62 3.69 3.19 20 1 0 4 2 9 Merc … 22.8 4 141. 95 3.92 3.15 22.9 1 0 4 2 10 Merc … 19.2 6 168. 123 3.92 3.44 18.3 1 0 4 4 # … with 22 more rows We can compute different summaries over the variables in a dataset. mtcars1 %&gt;% summarize(mpg = mean(mpg, na.rm=T), disp = mean(disp, na.rm=T), hp = mean(hp, na.rm=T)) # A tibble: 1 x 3 mpg disp hp &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 20.1 231. 147. "],
["scoped-verbs.html", "7.1 Scoped verbs", " 7.1 Scoped verbs All the dplyr verbs have scoped versions *_all, *_at and *_if. *_all : Act on all columns *_at : Act on specified columns *_if : Act on columns with specific property "],
["factors-categorical-variables.html", "7.2 Factors (categorical variables)", " 7.2 Factors (categorical variables) factor types of variables are discrete or categorical variables, that only take a small set of values. Think number of cylinders in a car, race, sex. We can covert a variable to a factor using as.factor. (There are also as.numeric and as.character). dos %&gt;% mutate_at(vars(ends_with(&quot;Date&quot;)), as_date) %&gt;% summarise_if(is.Date, max) # A tibble: 1 x 4 Award_Start_Date Award_End_Date Award_Transaction_Da… Data_Submission_Da… &lt;date&gt; &lt;date&gt; &lt;date&gt; &lt;date&gt; 1 NA NA 2017-10-03 2018-02-15 Here, we notice that a couple of the values are NA. We would like to add the na.rm=T option into the mean function. We can do that, as long as we put a ~ before it. The . is a place holder for each variable that will be interrogated here. dos %&gt;% mutate_at(vars(ends_with(&quot;Date&quot;)), as_date) %&gt;% summarize_at(vars(ends_with(&quot;Date&quot;)), ~max(., na.rm=T)) # A tibble: 1 x 4 Award_Start_Date Award_End_Date Award_Transaction_Da… Data_Submission_Da… &lt;date&gt; &lt;date&gt; &lt;date&gt; &lt;date&gt; 1 2018-09-30 2026-08-31 2017-10-03 2018-02-15 mtcars1 &lt;- mtcars1 %&gt;% mutate_at(vars(cyl, vs, am, gear, carb), as.factor) str(mtcars1) Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 32 obs. of 12 variables: $ cars: chr &quot;Mazda RX4&quot; &quot;Mazda RX4 Wag&quot; &quot;Datsun 710&quot; &quot;Hornet 4 Drive&quot; ... $ mpg : num 21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ... $ cyl : Factor w/ 3 levels &quot;4&quot;,&quot;6&quot;,&quot;8&quot;: 2 2 1 2 3 2 3 1 1 2 ... $ disp: num 160 160 108 258 360 ... $ hp : num 110 110 93 110 175 105 245 62 95 123 ... $ drat: num 3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ... $ wt : num 2.62 2.88 2.32 3.21 3.44 ... $ qsec: num 16.5 17 18.6 19.4 17 ... $ vs : Factor w/ 2 levels &quot;0&quot;,&quot;1&quot;: 1 1 2 2 1 2 1 2 2 2 ... $ am : Factor w/ 2 levels &quot;0&quot;,&quot;1&quot;: 2 2 2 1 1 1 1 1 1 1 ... $ gear: Factor w/ 3 levels &quot;3&quot;,&quot;4&quot;,&quot;5&quot;: 2 2 2 1 1 1 1 2 2 2 ... $ carb: Factor w/ 6 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,..: 4 4 1 1 2 1 4 2 2 4 ... mtcars1 %&gt;% summarize_if(is.numeric, mean) # A tibble: 1 x 6 mpg disp hp drat wt qsec &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 20.1 231. 147. 3.60 3.22 17.8 "],
["split-apply-combine.html", "Chapter 8 Split-apply-combine", " Chapter 8 Split-apply-combine Here, we compute summaries (means) by levels of cylinders. mtcars1 %&gt;% group_by(cyl) %&gt;% summarize(mpg_mean = mean(mpg)) # A tibble: 3 x 2 cyl mpg_mean &lt;fct&gt; &lt;dbl&gt; 1 4 26.7 2 6 19.7 3 8 15.1 We can still use scoped verbs if we want. mtcars1 %&gt;% group_by(cyl) %&gt;% summarize_if(is.numeric, mean) # A tibble: 3 x 7 cyl mpg disp hp drat wt qsec &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 4 26.7 105. 82.6 4.07 2.29 19.1 2 6 19.7 183. 122. 3.59 3.12 18.0 3 8 15.1 353. 209. 3.23 4.00 16.8 We can also do several summaries in one go. mtcars1 %&gt;% group_by(cyl) %&gt;% summarize_if(is.numeric, list(&#39;mean&#39; = mean, &#39;median&#39; = median)) # A tibble: 3 x 13 cyl mpg_mean disp_mean hp_mean drat_mean wt_mean qsec_mean mpg_median &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 4 26.7 105. 82.6 4.07 2.29 19.1 26 2 6 19.7 183. 122. 3.59 3.12 18.0 19.7 3 8 15.1 353. 209. 3.23 4.00 16.8 15.2 # … with 5 more variables: disp_median &lt;dbl&gt;, hp_median &lt;dbl&gt;, # drat_median &lt;dbl&gt;, wt_median &lt;dbl&gt;, qsec_median &lt;dbl&gt; Let’s go back to the DOS dataset. We’re going to see how much money was given to each implementatoin organization over the years. dos %&gt;% group_by(Implementing_Organization) %&gt;% summarize(amt = sum(Award_Transaction_Value)) %&gt;% arrange(desc(amt)) # A tibble: 9,236 x 2 Implementing_Organization amt &lt;chr&gt; &lt;dbl&gt; 1 United Nations High Commission 9548068186 2 &quot;&quot; 3374123507. 3 Information Redacted 3046872292. 4 Un Relief &amp; Works Agency 2975220114 5 Intl Committee - The Red Cross 2796820000 6 S/S-Ex Miscellanous Vendor 2433986355. 7 International Organization For Migration 1886668868. 8 P A E 961874214. 9 Pm Miscellaneous Vendor 925306561. 10 Un Childrens Fund 775056737. # … with 9,226 more rows We can also split by organization type dos %&gt;% group_by(Implementing_Organization_Type) %&gt;% summarize(amt = sum(Award_Transaction_Value)) %&gt;% arrange(desc(amt)) # A tibble: 4 x 2 Implementing_Organization_Type amt &lt;chr&gt; &lt;dbl&gt; 1 &quot;&quot; 36464252937. 2 Other Public Sector 4522645303. 3 Government 730826152. 4 Private Sector 714436474. If we want to look at time trends, we will also need to split by year, in addition to the organization. We’re using some lubridate code to make the years accessible to the computer. dos_by_year &lt;- dos %&gt;% group_by(Implementing_Organization, year = year(as_date(Award_Start_Date))) %&gt;% summarize(amt = sum(Award_Transaction_Value)) %&gt;% filter(Implementing_Organization != &#39;&#39;, !is.na(year)) We can also look at the overall trends by year. dos_by_year %&gt;% group_by(year) %&gt;% summarize(amt = sum(amt)) # A tibble: 17 x 2 year amt &lt;dbl&gt; &lt;dbl&gt; 1 2002 24162 2 2003 4350 3 2004 -211515. 4 2005 24294032. 5 2006 65101. 6 2007 30762236. 7 2008 28449918. 8 2009 142067481. 9 2010 11081559. 10 2011 1482727259. 11 2012 7703229189. 12 2013 10598445712. 13 2014 9672512696. 14 2015 6228419232. 15 2016 915449161. 16 2017 860274841. 17 2018 2327908 "],
["graphics.html", "Chapter 9 Data visualization ", " Chapter 9 Data visualization "],
["ggplot2.html", "9.1 ggplot2", " 9.1 ggplot2 We’ll be primarily using ggplot2 in this workshop. Makes pretty good formatting choices out of the box Works like pipes!! Is declarative (tell it what you want) without getting caught up in minutae Strongly leverages data frames (good practice) Fast enough There are good templates if you want to change the look The ggplot2 package is a very flexible and (to me) intuitive way of visualizing data. It is based on the concept of layering elements on a canvas. This idea of layering graphics on a canvas is, to me, a nice way of building graphs A data.frame object Aesthetic mappings (aes) to say what data is used for what purpose in the viz x- and y-direction shapes, colors, lines A geometry object (geom) to say what to draw You can “layer” geoms on each other to build plots ggplot used pipes before pipes were a thing. However, it uses the + symbol for piping rather than the %&gt;% operator, since it pre-dates the tidyverse library(ggplot2) ggplot(mtcars, aes(x = wt, y = mpg)) + geom_point() A data.frame object: mtcars Aesthetic mapping: x-axis: wt y-axis: mpg Geometry: geom_point: draw points ggplot(mtcars, aes(x = wt, y = mpg)) + geom_point()+ geom_smooth() A data.frame object: mtcars Aesthetic mapping: x-axis: wt y-axis: mpg Geometry: geom_point: draw points geom_smooth: Add a layer which draws a best-fitting line Now we clean up the plot to make it presentable. "],
["single-continuous-variable.html", "9.2 Single continuous variable", " 9.2 Single continuous variable 9.2.1 Histogram dos &lt;- import(&#39;data/Department of State.csv&#39;) dos %&gt;% ggplot(aes(x = Award_Transaction_Value)) + geom_histogram() Change the axis to the log scale for better visual dos %&gt;% ggplot(aes(x = Award_Transaction_Value)) + geom_histogram()+ scale_x_log10() # x-axis on log scale 9.2.2 Density plot dos %&gt;% ggplot(aes(x = Award_Transaction_Value)) + geom_density()+ scale_x_log10() "],
["bar-plots.html", "9.3 Bar plots", " 9.3 Bar plots library(lubridate) dos %&gt;% group_by(year = year(as_date(Award_Start_Date))) %&gt;% summarize(amount = sum(Award_Transaction_Value)) %&gt;% ggplot(aes(x = year, y = amount)) + # Note change in pipe operator geom_bar(stat=&#39;identity&#39;) 9.3.1 Exercise Using the mtcars dataset in R, create: A histogram of the fuel efficiences (mpg) in the data set A bar plot of frequencies of number of cylinders (cyl) in the car ggplot(mtcars, aes(x = mpg)) + geom_histogram(binwidth=3) # ggplot(mtcars) + geom_histogram(aes(x = mpg), binwidth = 3) ggplot(mtcars, aes(x = factor(cyl))) + geom_bar() "],
["two-continuous-variables.html", "9.4 Two continuous variables", " 9.4 Two continuous variables 9.4.1 Adding a best fitting straight line ggplot(mtcars, aes(x = hp, y = mpg))+ geom_point()+ geom_smooth(method = &#39;lm&#39;) "],
["time-series.html", "9.5 Time series", " 9.5 Time series library(forecast) d &lt;- data.frame(x = 1:length(gas), y = gas) # Australian monthly gas production ggplot(d, aes(x, y)) + geom_line() 9.5.1 Exercise Create a scatter plot of sepal length and sepal width from the iris dataset, and add a smooth line through it "],
["continuous-variable-with-discrete-variable.html", "9.6 Continuous variable with discrete variable", " 9.6 Continuous variable with discrete variable 9.6.1 Boxplot dos %&gt;% ggplot(aes(x = factor(year(as_date(Award_Start_Date))), y = Award_Transaction_Value))+ geom_boxplot() + scale_y_log10()+ labs(x = &#39;Year&#39;) 9.6.2 Violin plot This is essetially a reflected density plot and gives a better sense of the data distribution dos %&gt;% ggplot(aes(x = factor(year(as_date(Award_Start_Date))), y = Award_Transaction_Value))+ geom_violin() + scale_y_log10()+ labs(x = &#39;Year&#39;) 9.6.3 Exercise Plot a boxplot of petal length by species using the iris dataset "],
["grouped-visualizations.html", "9.7 Grouped visualizations", " 9.7 Grouped visualizations We’re going to plot the change in aid provided to each country over time. To do this we need summaries by time and location grp_data &lt;- dos %&gt;% group_by(Recipient_Location, year = year(as_date(Award_Start_Date))) %&gt;% summarize(amt = sum(Award_Transaction_Value)) %&gt;% filter(str_detect(Recipient_Location, &#39;^C&#39;)) ggplot(grp_data, aes(x = year, y = amt, color=Recipient_Location))+ geom_line()+ scale_y_log10() ggplot(grp_data, aes(x = year, y = amt))+ geom_line()+ scale_y_log10()+ facet_wrap(~Recipient_Location) ## dos %&gt;% filter(str_detect(Recipient_Location, &#39;^C&#39;)) %&gt;% ## ggplot(aes(x = year(as_date(Award_Start_Date)), ## y = Award_Transaction_Value, ## color = Recipient_Location, ## shape = Award_Transaction_Type))+ ## geom_point()+ ## labs(x = &#39;Year&#39;, color=&#39;Location&#39;)+ ## scale_y_log10() ## ## dos %&gt;% filter(str_detect(Recipient_Location, &#39;^C&#39;)) %&gt;% ## ggplot(aes(x = year(as_date(Award_Start_Date)), ## y = Award_Transaction_Value, ## color = Recipient_Location, ## shape = Award_Transaction_Type))+ ## geom_jitter()+ ## labs(x = &#39;Year&#39;, color=&#39;Location&#39;)+ ## scale_y_log10() ## schools &lt;- rio::import(&#39;data/schools.rds&#39;) schools %&gt;% filter(tophead==&#39;Elementary schools&#39;, head2==&quot;Average hours in school day&quot;) %&gt;% filter(!is.na(State), State != &#39;United States&#39;) %&gt;% ggplot(aes(x = State, y = stats, ymin = stats - 2*se, ymax = stats + 2*se)) + geom_pointrange()+ labs(y = &#39;Avg hours in school day&#39;)+ theme_bw()+ theme(axis.text.x = element_text(angle=45, hjust = 1)) "],
["maps.html", "9.8 Maps", " 9.8 Maps We can also ingest SHP files to draw maps. We don’t show the final version since it took too long to render. library(sf) hrr_info &lt;- st_read(&#39;~/Downloads/hrr_bdry-1/HRR_Bdry.SHP&#39;) head(hrr_info) ggplot(hrr_info)+geom_sf() ggsave(&#39;map.png&#39;) "],
["stitching-graphs-together-.html", "9.9 Stitching graphs together.", " 9.9 Stitching graphs together. # install.packages(&#39;cowplot&#39;) library(cowplot) p1 &lt;- ggplot(iris, aes(Sepal.Length, Sepal.Width, color = Species)) + geom_point() + facet_grid(. ~ Species) + stat_smooth(method = &quot;lm&quot;) + background_grid(major = &#39;y&#39;, minor = &quot;none&quot;) + panel_border() + theme(legend.position = &quot;none&quot;) # plot B p2 &lt;- ggplot(iris, aes(Sepal.Length, fill = Species)) + geom_density(alpha = .7) + theme(legend.justification = &quot;top&quot;) p2a &lt;- p2 + theme(legend.position = &quot;none&quot;) # plot C p3 &lt;- ggplot(iris, aes(Sepal.Width, fill = Species)) + geom_density(alpha = .7) + theme(legend.position = &quot;none&quot;) # legend legend &lt;- get_legend(p2) # align all plots vertically plots &lt;- align_plots(p1, p2a, p3, align = &#39;v&#39;, axis = &#39;l&#39;) # put together bottom row and then everything bottom_row &lt;- plot_grid(plots[[2]], plots[[3]], legend, labels = c(&quot;B&quot;, &quot;C&quot;), rel_widths = c(1, 1, .3), nrow = 1) plot_grid(plots[[1]], bottom_row, labels = c(&quot;A&quot;), ncol = 1) ## library(ggplot2) ## library(plotly) ## p=ggplot(iris, aes(x=Sepal.Length, ## y=Sepal.Width, ## color=Species, ## shape=Species)) + ## geom_point(size=6, alpha=0.6) ## mytext=paste(&quot;Sepal Length = &quot;, iris$Sepal.Length, ## &quot;\\n&quot; , &quot;Sepal Width = &quot;, iris$Sepal.Width, ## &quot;\\n&quot;, &quot;Row Number: &quot;,rownames(iris), sep=&quot;&quot;) ## pp=plotly::plotly_build(p) ## style( pp, text=mytext, ## hoverinfo = &quot;text&quot;, ## traces = c(1, 2, 3) ) "],
["interactive.html", "9.10 Interactive graphics", " 9.10 Interactive graphics We won’t put these in the notes, since they don’t work well in printed form "],
["functions.html", "Chapter 10 Functions", " Chapter 10 Functions myDumbFunction &lt;- function() 42 myDumbFunction() [1] 42 doubleIt &lt;- function(x) { myResult &lt;- x * 2 myResult # or, explicitly, return(myResult) } doubleIt(5) [1] 10 exists(&quot;myResult&quot;) [1] FALSE myResult &lt;- 1000 doubleItOutput &lt;- doubleIt(2) myResult [1] 1000 my_sum &lt;- function(x){ s &lt;- sum(x) n &lt;- length(x) result &lt;- s / n return(result) } my_sum(1:10) [1] 5.5 answer &lt;- my_sum(1:10) answer [1] 5.5 my_sum &lt;- function(x){ s &lt;- sum(x) n &lt;- length(x) results&lt;- list(sum = s, length = n, answer = s / n) return(results) } my_sum(1:10) $sum [1] 55 $length [1] 10 $answer [1] 5.5 my_sum &lt;- function(x){ s &lt;- sum(x) n &lt;- length(x) results&lt;- list(sum = s, length = n, answer = s / n) return(results) } answer &lt;- my_sum(1:10) answer$answer [1] 5.5 answer[[&#39;answer&#39;]] [1] 5.5 names(answer) [1] &quot;sum&quot; &quot;length&quot; &quot;answer&quot; x &lt;- 1:10 x[3] &lt;- NA my_sum(x) $sum [1] NA $length [1] 10 $answer [1] NA my_sum &lt;- function(x){ s &lt;- sum(x, na.rm=T) n &lt;- length(!is.na(x)) results &lt;- list(&quot;sum&quot; = s, &quot;length&quot; = n, &quot;answer&quot; = s/n) } my_sum(x) my_sum &lt;- function(x){ s &lt;- sum(x, na.rm = T) n &lt;- length(!is.na(x)) results &lt;- list(&quot;sum&quot; = s, &quot;length&quot; = n, &quot;answer&quot; = s/n) return(results) #&lt;&lt; } my_sum(x) $sum [1] 52 $length [1] 10 $answer [1] 5.2 my_sum &lt;- function(x){ s &lt;- sum(x, na.rm = T) n &lt;- length(!is.na(x)) results &lt;- list(&quot;sum&quot; = s, &quot;length&quot; = n, &quot;answer&quot; = s/n) return(results) } my_sum &lt;- function(x){ s &lt;- sum(x, na.rm = T) {{ n &lt;- sum(!is.na(x)) }} results &lt;- list(&quot;sum&quot; = s, &quot;length&quot; = n, &quot;answer&quot; = s/n) return(results) } my_sum(x) $sum [1] 52 $length [1] 9 $answer [1] 5.777778 my_sum &lt;- function(x){ s &lt;- sum(x, na.rm = T) n &lt;- sum(!is.na(x)) results &lt;- list(&quot;sum&quot; = s, &quot;length&quot; = n, &quot;answer&quot; = s/n) return(results) } my_sum &lt;- function(x, remove_missing = TRUE){ #&lt;&lt; s &lt;- sum(x, na.rm = T) n &lt;- sum(!is.na(x)) results &lt;- list(&quot;sum&quot; = s, &quot;length&quot; = n, &quot;answer&quot; = s/n) return(results) } my_sum &lt;- function(x, remove_missing = TRUE){ {{if(remove_missing){ x &lt;- x[!is.na(x)] } s &lt;- sum(x) n &lt;- length(x)}} results &lt;- list(&quot;sum&quot; = s, &quot;length&quot; = n, &quot;answer&quot; = s/n) return(results) } my_sum(x) $sum [1] 52 $length [1] 9 $answer [1] 5.777778 my_sum &lt;- function(x, remove_missing = TRUE){ if(remove_missing){ x &lt;- x[!is.na(x)] } s &lt;- sum(x) n &lt;- length(x) results &lt;- list(&quot;sum&quot; = s, &quot;length&quot; = n, &quot;answer&quot; = s/n, &quot;nmiss&quot; = sum(is.na(x))) return(results) } my_sum(x) $sum [1] 52 $length [1] 9 $answer [1] 5.777778 $nmiss [1] 0 my_sum &lt;- function(x, remove_missing = TRUE){ nmiss &lt;- sum(is.na(x)) #&lt;&lt; if(remove_missing){ x &lt;- x[!is.na(x)] } s &lt;- sum(x) n &lt;- length(x) results &lt;- list(&quot;sum&quot; = s, &quot;length&quot; = n, &quot;answer&quot; = s/n, &quot;nmiss&quot; = sum(is.na(x))) return(results) } my_sum(x) $sum [1] 52 $length [1] 9 $answer [1] 5.777778 $nmiss [1] 0 my_sum &lt;- function(x, remove_missing = TRUE){ nmiss &lt;- sum(is.na(x)) if(remove_missing){ x &lt;- x[!is.na(x)] } s &lt;- sum(x) n &lt;- length(x) results &lt;- list(&quot;sum&quot; = s, &quot;length&quot; = n, &quot;answer&quot; = s/n, &quot;nmiss&quot; = nmiss) #&lt;&lt; return(results) } my_sum(x) $sum [1] 52 $length [1] 9 $answer [1] 5.777778 $nmiss [1] 1 my_sum(x, remove_missing = F) $sum [1] NA $length [1] 10 $answer [1] NA $nmiss [1] 1 my_summary &lt;- function(d){ } my_summary &lt;- function(d){ require(tidyverse) #&lt; } my_summary &lt;- function(d){ require(tidyverse) summary_cts &lt;- d %&gt;% summarize_if(is.numeric, list(&quot;mean&quot; = ~mean(x, na.rm=T), &quot;median&quot; = ~median(x, na.rm=T), &#39;sd&#39; = ~sd(x, na.rm=T), &#39;nmiss&#39; = ~sum(is.na(x)))) return(list(&quot;cts&quot; = summary_cts)) } my_summary(iris) Loading required package: tidyverse ── Attaching packages ───────────────────────────── tidyverse 1.2.1 ── ✔ ggplot2 3.1.0 ✔ purrr 0.3.2 ✔ tibble 2.0.1 ✔ dplyr 0.8.0.9009 ✔ tidyr 0.8.3 ✔ stringr 1.4.0 ✔ readr 1.3.1 ✔ forcats 0.4.0 Warning: package &#39;tibble&#39; was built under R version 3.5.2 Warning: package &#39;tidyr&#39; was built under R version 3.5.2 Warning: package &#39;stringr&#39; was built under R version 3.5.2 ── Conflicts ──────────────────────────────── tidyverse_conflicts() ── ✖ dplyr::filter() masks stats::filter() ✖ dplyr::lag() masks stats::lag() $cts Sepal.Length_mean Sepal.Width_mean Petal.Length_mean Petal.Width_mean 1 5.777778 5.777778 5.777778 5.777778 Sepal.Length_median Sepal.Width_median Petal.Length_median 1 6 6 6 Petal.Width_median Sepal.Length_sd Sepal.Width_sd Petal.Length_sd 1 6 3.073181 3.073181 3.073181 Petal.Width_sd Sepal.Length_nmiss Sepal.Width_nmiss Petal.Length_nmiss 1 3.073181 1 1 1 Petal.Width_nmiss 1 1 my_summary &lt;- function(d){ require(tidyverse) summary_cts &lt;- d %&gt;% summarize_if(is.numeric, list(&quot;mean&quot; = ~mean(x, na.rm=T), &quot;median&quot; = ~median(x, na.rm=T), &#39;sd&#39; = ~sd(x, na.rm=T), &#39;nmiss&#39; = ~sum(is.na(x)))) %&gt;% gather(variable, value) %&gt;% separate(variable, c(&quot;variable&quot;,&quot;stat&quot;), sep=&#39;_&#39;) %&gt;% spread(stat, value) return(list(&quot;cts&quot; = summary_cts)) } my_summary(iris) $cts variable mean median nmiss sd 1 Petal.Length 5.777778 6 1 3.073181 2 Petal.Width 5.777778 6 1 3.073181 3 Sepal.Length 5.777778 6 1 3.073181 4 Sepal.Width 5.777778 6 1 3.073181 my_summary &lt;- function(d){ require(tidyverse) summary_cts &lt;- d %&gt;% summarize_if(is.numeric, list(&quot;mean&quot; = ~mean(x, na.rm=T), #&lt;&lt; &quot;median&quot; = ~median(x, na.rm=T),#&lt;&lt; &#39;sd&#39; = ~sd(x, na.rm=T),#&lt;&lt; &#39;nmiss&#39; = ~sum(is.na(x)))) %&gt;% #&lt;&lt; gather(variable, value) %&gt;% separate(variable, c(&quot;variable&quot;,&quot;stat&quot;), sep=&#39;_&#39;) %&gt;% spread(stat, value) return(list(&quot;cts&quot; = summary_cts)) } my_summary(iris) $cts variable mean median nmiss sd 1 Petal.Length 5.777778 6 1 3.073181 2 Petal.Width 5.777778 6 1 3.073181 3 Sepal.Length 5.777778 6 1 3.073181 4 Sepal.Width 5.777778 6 1 3.073181 my_summary &lt;- function(d){ require(tidyverse) summary_cts &lt;- d %&gt;% summarize_if(is.numeric, list(&quot;mean&quot; = ~mean(., na.rm=T),#&lt;&lt; &quot;median&quot; = ~median(., na.rm=T),#&lt;&lt; &#39;sd&#39; = ~sd(., na.rm=T),#&lt;&lt; &#39;nmiss&#39; = ~sum(is.na(.)))) %&gt;% #&lt;&lt; gather(variable, value) %&gt;% separate(variable, c(&quot;variable&quot;,&quot;stat&quot;), sep=&#39;_&#39;) %&gt;% spread(stat, value) return(list(&quot;cts&quot; = summary_cts)) } my_summary(iris) $cts variable mean median nmiss sd 1 Petal.Length 3.758000 4.35 0 1.7652982 2 Petal.Width 1.199333 1.30 0 0.7622377 3 Sepal.Length 5.843333 5.80 0 0.8280661 4 Sepal.Width 3.057333 3.00 0 0.4358663 my_summary &lt;- function(d){ require(tidyverse) summary_cts &lt;- d %&gt;% summarize_if(is.numeric, list(&quot;mean&quot; = ~mean(., na.rm=T), &quot;median&quot; = ~median(., na.rm=T), &#39;sd&#39; = ~sd(., na.rm=T), &#39;nmiss&#39; = ~sum(is.na(.)))) %&gt;% gather(variable, value) %&gt;% separate(variable, c(&quot;variable&quot;,&quot;stat&quot;), sep=&#39;_&#39;) %&gt;% spread(stat, value) %&gt;% select(variable, nmiss, everything()) #&lt;&lt; return(list(&quot;cts&quot; = summary_cts)) } my_summary(iris) $cts variable nmiss mean median sd 1 Petal.Length 0 3.758000 4.35 1.7652982 2 Petal.Width 0 1.199333 1.30 0.7622377 3 Sepal.Length 0 5.843333 5.80 0.8280661 4 Sepal.Width 0 3.057333 3.00 0.4358663 my_summary &lt;- function(d){ require(tidyverse) summary_cts &lt;- d %&gt;% summarize_if(is.numeric, list(&quot;mean&quot; = ~mean(., na.rm=T), &quot;median&quot; = ~median(., na.rm=T), &#39;sd&#39; = ~sd(., na.rm=T), &#39;nmiss&#39; = ~sum(is.na(.)))) %&gt;% gather(variable, value) %&gt;% separate(variable, c(&quot;variable&quot;,&quot;stat&quot;), sep=&#39;_&#39;) %&gt;% spread(stat, value) %&gt;% select(variable, nmiss, everything()) summary_cat &lt;- d %&gt;% #&lt;&lt; summarise_if(is.factor, list(&#39;nmiss&#39; = ~sum(is.na(.)),#&lt;&lt; &#39;ncat&#39; = ~length(unique(.)),#&lt;&lt; &#39;categories&#39; = ~paste(sort(unique(levels(.))), collapse=&#39;, &#39;)) #&lt;&lt; )#&lt;&lt; return(list(&quot;cts&quot; = summary_cts, &quot;cat&quot; = summary_cat)) } my_summary(iris) $cts variable nmiss mean median sd 1 Petal.Length 0 3.758000 4.35 1.7652982 2 Petal.Width 0 1.199333 1.30 0.7622377 3 Sepal.Length 0 5.843333 5.80 0.8280661 4 Sepal.Width 0 3.057333 3.00 0.4358663 $cat nmiss ncat categories 1 0 3 setosa, versicolor, virginica my_summary &lt;- function(d){ require(tidyverse) if(!is.data.frame(d)){#&lt;&lt; stop(&quot;Input must be a data.frame&quot;)#&lt;&lt; }#&lt;&lt; summary_cts &lt;- d %&gt;% summarize_if(is.numeric, list(&quot;mean&quot; = ~mean(., na.rm=T), &quot;median&quot; = ~median(., na.rm=T), &#39;sd&#39; = ~sd(., na.rm=T), &#39;nmiss&#39; = ~sum(is.na(.)))) %&gt;% gather(variable, value) %&gt;% separate(variable, c(&quot;variable&quot;,&quot;stat&quot;), sep=&#39;_&#39;) %&gt;% spread(stat, value) %&gt;% select(variable, nmiss, everything()) summary_cat &lt;- d %&gt;% summarise_if(is.factor, list(&#39;nmiss&#39; = ~sum(is.na(.)), &#39;ncat&#39; = ~length(unique(.)), &#39;categories&#39; = ~paste(sort(unique(levels(.))), collapse=&#39;, &#39;)) ) return(list(&quot;cts&quot; = summary_cts, &quot;cat&quot; = summary_cat)) } my_summary(x) datas &lt;- list(&#39;cars&#39; = mtcars, &#39;iris&#39; = iris, &#39;diamonds&#39;= diamonds) map(datas, my_summary) $cars $cars$cts variable nmiss mean median sd 1 am 0 0.406250 0.000 0.4989909 2 carb 0 2.812500 2.000 1.6152000 3 cyl 0 6.187500 6.000 1.7859216 4 disp 0 230.721875 196.300 123.9386938 5 drat 0 3.596563 3.695 0.5346787 6 gear 0 3.687500 4.000 0.7378041 7 hp 0 146.687500 123.000 68.5628685 8 mpg 0 20.090625 19.200 6.0269481 9 qsec 0 17.848750 17.710 1.7869432 10 vs 0 0.437500 0.000 0.5040161 11 wt 0 3.217250 3.325 0.9784574 $cars$cat data frame with 0 columns and 1 row $iris $iris$cts variable nmiss mean median sd 1 Petal.Length 0 3.758000 4.35 1.7652982 2 Petal.Width 0 1.199333 1.30 0.7622377 3 Sepal.Length 0 5.843333 5.80 0.8280661 4 Sepal.Width 0 3.057333 3.00 0.4358663 $iris$cat nmiss ncat categories 1 0 3 setosa, versicolor, virginica $diamonds $diamonds$cts # A tibble: 7 x 5 variable nmiss mean median sd &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 carat 0 0.798 0.7 0.474 2 depth 0 61.7 61.8 1.43 3 price 0 3933. 2401 3989. 4 table 0 57.5 57 2.23 5 x 0 5.73 5.7 1.12 6 y 0 5.73 5.71 1.14 7 z 0 3.54 3.53 0.706 $diamonds$cat # A tibble: 1 x 9 cut_nmiss color_nmiss clarity_nmiss cut_ncat color_ncat clarity_ncat &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; 1 0 0 0 5 7 8 # … with 3 more variables: cut_categories &lt;chr&gt;, color_categories &lt;chr&gt;, # clarity_categories &lt;chr&gt; "],
["modeling.html", "Chapter 11 Modeling", " Chapter 11 Modeling library(survival) data(pbc) str(pbc) &#39;data.frame&#39;: 418 obs. of 20 variables: $ id : int 1 2 3 4 5 6 7 8 9 10 ... $ time : int 400 4500 1012 1925 1504 2503 1832 2466 2400 51 ... $ status : int 2 0 2 2 1 2 0 2 2 2 ... $ trt : int 1 1 1 1 2 2 2 2 1 2 ... $ age : num 58.8 56.4 70.1 54.7 38.1 ... $ sex : Factor w/ 2 levels &quot;m&quot;,&quot;f&quot;: 2 2 1 2 2 2 2 2 2 2 ... $ ascites : int 1 0 0 0 0 0 0 0 0 1 ... $ hepato : int 1 1 0 1 1 1 1 0 0 0 ... $ spiders : int 1 1 0 1 1 0 0 0 1 1 ... $ edema : num 1 0 0.5 0.5 0 0 0 0 0 1 ... $ bili : num 14.5 1.1 1.4 1.8 3.4 0.8 1 0.3 3.2 12.6 ... $ chol : int 261 302 176 244 279 248 322 280 562 200 ... $ albumin : num 2.6 4.14 3.48 2.54 3.53 3.98 4.09 4 3.08 2.74 ... $ copper : int 156 54 210 64 143 50 52 52 79 140 ... $ alk.phos: num 1718 7395 516 6122 671 ... $ ast : num 137.9 113.5 96.1 60.6 113.2 ... $ trig : int 172 88 55 92 72 63 213 189 88 143 ... $ platelet: int 190 221 151 183 136 NA 204 373 251 302 ... $ protime : num 12.2 10.6 12 10.3 10.9 11 9.7 11 11 11.5 ... $ stage : int 4 3 4 4 3 3 3 3 2 4 ... myLinearModel &lt;- lm(chol ~ bili, data = pbc) myLinearModel Call: lm(formula = chol ~ bili, data = pbc) Coefficients: (Intercept) bili 303.20 20.24 summary(myLinearModel) Call: lm(formula = chol ~ bili, data = pbc) Residuals: Min 1Q Median 3Q Max -565.39 -89.90 -35.36 44.92 1285.33 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 303.204 15.601 19.435 &lt; 2e-16 *** bili 20.240 2.785 7.267 3.63e-12 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 213.2 on 282 degrees of freedom (134 observations deleted due to missingness) Multiple R-squared: 0.1577, Adjusted R-squared: 0.1547 F-statistic: 52.8 on 1 and 282 DF, p-value: 3.628e-12 broom::tidy(myLinearModel) # A tibble: 2 x 5 term estimate std.error statistic p.value &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 (Intercept) 303. 15.6 19.4 5.65e-54 2 bili 20.2 2.79 7.27 3.63e-12 broom::glance(myLinearModel) # A tibble: 1 x 11 r.squared adj.r.squared sigma statistic p.value df logLik AIC BIC &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 0.158 0.155 213. 52.8 3.63e-12 2 -1925. 3856. 3867. # … with 2 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt; ## # install.packages(&#39;ggfortify&#39;) ## library(ggfortify) ## autoplot(myLinearModel) ## ggplot(pbc, aes(x = bili))+geom_density() ## ggplot(pbc, aes(x = log(bili)))+geom_density() myLinearModel2 &lt;- lm(chol~log(bili), data = pbc) summary(myLinearModel2) Call: lm(formula = chol ~ log(bili), data = pbc) Residuals: Min 1Q Median 3Q Max -440.07 -94.35 -21.07 42.67 1221.86 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 311.48 14.28 21.816 &lt; 2e-16 *** log(bili) 98.80 12.07 8.186 9.42e-15 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 208.9 on 282 degrees of freedom (134 observations deleted due to missingness) Multiple R-squared: 0.192, Adjusted R-squared: 0.1891 F-statistic: 67.01 on 1 and 282 DF, p-value: 9.416e-15 autoplot(myLinearModel2) autoplot(myLinearModel2, which=1) d &lt;- broom::augment(myLinearModel2) d # A tibble: 284 x 10 .rownames chol log.bili. .fitted .se.fit .resid .hat .sigma .cooksd &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 1 261 2.67 576. 28.1 -315. 0.0181 208. 2.13e-2 2 2 302 0.0953 321. 13.7 -18.9 0.00433 209. 1.79e-5 3 3 176 0.336 345. 12.8 -169. 0.00373 209. 1.23e-3 4 4 244 0.588 370. 12.4 -126. 0.00352 209. 6.41e-4 5 5 279 1.22 432. 14.6 -153. 0.00487 209. 1.33e-3 6 6 248 -0.223 289. 15.8 -41.4 0.00571 209. 1.14e-4 7 7 322 0 311. 14.3 10.5 0.00467 209. 5.98e-6 8 8 280 -1.20 193. 24.9 87.5 0.0142 209. 1.28e-3 9 9 562 1.16 426. 14.2 136. 0.00463 209. 9.84e-4 10 10 200 2.53 562. 26.6 -362. 0.0162 208. 2.51e-2 # … with 274 more rows, and 1 more variable: .std.resid &lt;dbl&gt; ggplot(d, aes(x = .fitted, y = .resid))+geom_point()+ geom_smooth(se=F)+ labs(x = &#39;Fitted values&#39;, y = &#39;Residual values&#39;) head(predict(myLinearModel2, newdata = pbc)) 1 2 3 4 5 6 575.6925 320.9006 344.7277 369.5578 432.3941 289.4371 myLM3 &lt;- lm(chol ~ log(bili) + sex, data = pbc) broom::tidy(myLM3) # A tibble: 3 x 5 term estimate std.error statistic p.value &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 (Intercept) 283. 36.6 7.71 2.14e-13 2 log(bili) 99.6 12.1 8.22 7.37e-15 3 sexf 32.5 37.8 0.858 3.92e- 1 myLR &lt;- glm(spiders ~ albumin + bili + chol, data = pbc, family = binomial) myLR Call: glm(formula = spiders ~ albumin + bili + chol, family = binomial, data = pbc) Coefficients: (Intercept) albumin bili chol 2.3326484 -0.9954927 0.0995915 -0.0003176 Degrees of Freedom: 283 Total (i.e. Null); 280 Residual (134 observations deleted due to missingness) Null Deviance: 341.4 Residual Deviance: 315.2 AIC: 323.2 broom::tidy(myLR) # A tibble: 4 x 5 term estimate std.error statistic p.value &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 (Intercept) 2.33 1.30 1.80 0.0717 2 albumin -0.995 0.362 -2.75 0.00595 3 bili 0.0996 0.0344 2.89 0.00381 4 chol -0.000318 0.000615 -0.517 0.605 broom::glance(myLR) # A tibble: 1 x 7 null.deviance df.null logLik AIC BIC deviance df.residual &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; 1 341. 283 -158. 323. 338. 315. 280 head(predict(myLR)) 1 2 3 4 5 6 1.10554163 -1.77506554 -1.04814132 -0.09414055 -0.93144911 -1.62851203 head(predict(myLR, type=&#39;response&#39;)) 1 2 3 4 5 6 0.7512970 0.1449135 0.2595822 0.4764822 0.2826308 0.1640343 "],
["model-selection.html", "11.1 Model selection", " 11.1 Model selection # install.packages(&#39;leaps&#39;) library(leaps) mtcars1 &lt;- mtcars %&gt;% mutate_at(vars(cyl, vs:carb), as.factor) all_subsets &lt;- regsubsets(mpg~., data = mtcars1) all_subsets Subset selection object Call: regsubsets.formula(mpg ~ ., data = mtcars1) 16 Variables (and intercept) Forced in Forced out cyl6 FALSE FALSE cyl8 FALSE FALSE disp FALSE FALSE hp FALSE FALSE drat FALSE FALSE wt FALSE FALSE qsec FALSE FALSE vs1 FALSE FALSE am1 FALSE FALSE gear4 FALSE FALSE gear5 FALSE FALSE carb2 FALSE FALSE carb3 FALSE FALSE carb4 FALSE FALSE carb6 FALSE FALSE carb8 FALSE FALSE 1 subsets of each size up to 8 Selection Algorithm: exhaustive ind &lt;- which.max(summary(all_subsets)$adjr2) summary(all_subsets)$which[ind,] (Intercept) cyl6 cyl8 disp hp drat TRUE TRUE FALSE FALSE TRUE FALSE wt qsec vs1 am1 gear4 gear5 TRUE FALSE TRUE TRUE FALSE FALSE carb2 carb3 carb4 carb6 carb8 FALSE FALSE FALSE FALSE FALSE "],
["many-models.html", "11.2 Many models", " 11.2 Many models mtcars &lt;- as_tibble(mtcars) mtcars %&gt;% select(mpg, disp:qsec) # A tibble: 32 x 6 mpg disp hp drat wt qsec &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 21 160 110 3.9 2.62 16.5 2 21 160 110 3.9 2.88 17.0 3 22.8 108 93 3.85 2.32 18.6 4 21.4 258 110 3.08 3.22 19.4 5 18.7 360 175 3.15 3.44 17.0 6 18.1 225 105 2.76 3.46 20.2 7 14.3 360 245 3.21 3.57 15.8 8 24.4 147. 62 3.69 3.19 20 9 22.8 141. 95 3.92 3.15 22.9 10 19.2 168. 123 3.92 3.44 18.3 # … with 22 more rows mtcars %&gt;% select(mpg, disp:qsec) %&gt;% gather(variable, value, -mpg) # A tibble: 160 x 3 mpg variable value &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; 1 21 disp 160 2 21 disp 160 3 22.8 disp 108 4 21.4 disp 258 5 18.7 disp 360 6 18.1 disp 225 7 14.3 disp 360 8 24.4 disp 147. 9 22.8 disp 141. 10 19.2 disp 168. # … with 150 more rows mtcars %&gt;% select(mpg, disp:qsec) %&gt;% gather(variable, value, -mpg) %&gt;% group_by(variable) %&gt;% lm(mpg~value, data=.) Call: lm(formula = mpg ~ value, data = .) Coefficients: (Intercept) value 21.28328 -0.01483 mtcars %&gt;% select(mpg, disp:qsec) %&gt;% gather(variable, value, -mpg) %&gt;% nest(-variable) # A tibble: 5 x 2 variable data &lt;chr&gt; &lt;list&gt; 1 disp &lt;tibble [32 × 2]&gt; 2 hp &lt;tibble [32 × 2]&gt; 3 drat &lt;tibble [32 × 2]&gt; 4 wt &lt;tibble [32 × 2]&gt; 5 qsec &lt;tibble [32 × 2]&gt; bl &lt;- mtcars %&gt;% select(mpg, disp:qsec) %&gt;% gather(variable, value, -mpg) %&gt;% nest(-variable) bl$data[[1]] # A tibble: 32 x 2 mpg value &lt;dbl&gt; &lt;dbl&gt; 1 21 160 2 21 160 3 22.8 108 4 21.4 258 5 18.7 360 6 18.1 225 7 14.3 360 8 24.4 147. 9 22.8 141. 10 19.2 168. # … with 22 more rows mtcars %&gt;% select(mpg, disp:qsec) %&gt;% gather(variable, value, -mpg) %&gt;% nest(-variable) %&gt;% mutate(models = map(data, ~lm(mpg~value, data=.))) # A tibble: 5 x 3 variable data models &lt;chr&gt; &lt;list&gt; &lt;list&gt; 1 disp &lt;tibble [32 × 2]&gt; &lt;S3: lm&gt; 2 hp &lt;tibble [32 × 2]&gt; &lt;S3: lm&gt; 3 drat &lt;tibble [32 × 2]&gt; &lt;S3: lm&gt; 4 wt &lt;tibble [32 × 2]&gt; &lt;S3: lm&gt; 5 qsec &lt;tibble [32 × 2]&gt; &lt;S3: lm&gt; mtcars %&gt;% select(mpg, disp:qsec) %&gt;% gather(variable, value, -mpg) %&gt;% nest(-variable) %&gt;% mutate(models = map(data, ~lm(mpg~value, data=.)), outputs = map(models, ~tidy(.))) # A tibble: 5 x 4 variable data models outputs &lt;chr&gt; &lt;list&gt; &lt;list&gt; &lt;list&gt; 1 disp &lt;tibble [32 × 2]&gt; &lt;S3: lm&gt; &lt;tibble [2 × 5]&gt; 2 hp &lt;tibble [32 × 2]&gt; &lt;S3: lm&gt; &lt;tibble [2 × 5]&gt; 3 drat &lt;tibble [32 × 2]&gt; &lt;S3: lm&gt; &lt;tibble [2 × 5]&gt; 4 wt &lt;tibble [32 × 2]&gt; &lt;S3: lm&gt; &lt;tibble [2 × 5]&gt; 5 qsec &lt;tibble [32 × 2]&gt; &lt;S3: lm&gt; &lt;tibble [2 × 5]&gt; mtcars %&gt;% select(mpg, disp:qsec) %&gt;% gather(variable, value, -mpg) %&gt;% nest(-variable) %&gt;% mutate(models = map(data, ~lm(mpg~value, data=.)), outputs = map(models, ~tidy(.))) %&gt;% select(variable, outputs) # A tibble: 5 x 2 variable outputs &lt;chr&gt; &lt;list&gt; 1 disp &lt;tibble [2 × 5]&gt; 2 hp &lt;tibble [2 × 5]&gt; 3 drat &lt;tibble [2 × 5]&gt; 4 wt &lt;tibble [2 × 5]&gt; 5 qsec &lt;tibble [2 × 5]&gt; mtcars %&gt;% select(mpg, disp:qsec) %&gt;% gather(variable, value, -mpg) %&gt;% nest(-variable) %&gt;% mutate(models = map(data, ~lm(mpg~value, data=.)), outputs = map(models, ~tidy(.))) %&gt;% select(variable, outputs) %&gt;% unnest() # A tibble: 10 x 6 variable term estimate std.error statistic p.value &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 disp (Intercept) 29.6 1.23 24.1 3.58e-21 2 disp value -0.0412 0.00471 -8.75 9.38e-10 3 hp (Intercept) 30.1 1.63 18.4 6.64e-18 4 hp value -0.0682 0.0101 -6.74 1.79e- 7 5 drat (Intercept) -7.52 5.48 -1.37 1.80e- 1 6 drat value 7.68 1.51 5.10 1.78e- 5 7 wt (Intercept) 37.3 1.88 19.9 8.24e-19 8 wt value -5.34 0.559 -9.56 1.29e-10 9 qsec (Intercept) -5.11 10.0 -0.510 6.14e- 1 10 qsec value 1.41 0.559 2.53 1.71e- 2 mtcars %&gt;% select(mpg, disp:qsec) %&gt;% gather(variable, value, -mpg) %&gt;% nest(-variable) %&gt;% mutate(models = map(data, ~lm(mpg~value, data=.)), outputs = map(models, ~tidy(.))) %&gt;% select(variable, outputs) %&gt;% unnest() %&gt;% filter(term==&#39;value&#39;) # A tibble: 5 x 6 variable term estimate std.error statistic p.value &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 disp value -0.0412 0.00471 -8.75 9.38e-10 2 hp value -0.0682 0.0101 -6.74 1.79e- 7 3 drat value 7.68 1.51 5.10 1.78e- 5 4 wt value -5.34 0.559 -9.56 1.29e-10 5 qsec value 1.41 0.559 2.53 1.71e- 2 mtcars %&gt;% select(mpg, disp:qsec) %&gt;% gather(variable, value, -mpg) %&gt;% nest(-variable) %&gt;% mutate(models = map(data, ~lm(mpg~value, data=.)), outputs = map(models, ~tidy(.))) %&gt;% select(variable, outputs) %&gt;% unnest() %&gt;% filter(term==&#39;value&#39;) %&gt;% mutate_if(is.numeric, funs(round(., 3))) # A tibble: 5 x 6 variable term estimate std.error statistic p.value &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 disp value -0.041 0.005 -8.75 0 2 hp value -0.068 0.01 -6.74 0 3 drat value 7.68 1.51 5.10 0 4 wt value -5.34 0.559 -9.56 0 5 qsec value 1.41 0.559 2.52 0.017 "],
["predictive-modeling.html", "Chapter 12 Predictive modeling", " Chapter 12 Predictive modeling library(tidyverse) library(caret) data(diamonds) set.seed(12356) diamonds_train &lt;- diamonds %&gt;% sample_frac(size = 0.8) # 80% diamonds_test &lt;- anti_join(diamonds, diamonds_train) (nrow(diamonds) == nrow(diamonds_train) + nrow(diamonds_test)) [1] FALSE "]
]
